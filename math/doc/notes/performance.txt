I'd like to take these measurements from the command line
rather than through R.  

I don't care about 32-bit results.

We probably want to compare cross-platform and
cross-compiler (e.g., Windows/Mac/Linux g++/clang++).

I only care about optimization-level 3 results.  We
should be sure to compile JAGS that way, too.  I remember
there used to be some issue about how some of their
binaries were compiled.  


Per-Model Measurements
-----------------------

These are all per-model measurements that could be
scatterplotted.

1.  How long does it take to compile?

This is in some sense only relevant for Stan, because
BUGS and JAGS are compiled.


2.  How long does it take to read in data?

This step is actually linked to the model analysis step
in BUGS/JAGS because it's where they unfold the 
loops into a big graphical model and check that the
result is a directed acyclic graph.

Stan will thus read much faster because it's just a pure
read (of course, reading binary files would be
much faster I/O, but I/O is dominated by other factors).


2.  How long does it take to converge from a random initialization?

Equivalently, how long does it take to get 1 sample.

Equivalently, how long does it take to get near the posterior mean?  

The plan right now is to measure this by how long you have to run 
4 chains until the split R-hat on all parameters is less than 1.05.


3.  How long does it take to draw each subsequent effectively independent
sample?

For this, we have to evaluate ESS.  Daniel's implementing 
variograms.  I think he'll have some issues to discuss at the
next Stan meeting.


4.  How much contention is there from multiple sampling processes?  Threads?

By this, I mean if we run 4 (or more) sampling processes,
are they fighting over disk access?  Or memory/cache?  

This is also tricky to measure because the seek performance 
difference between a spinny disk and a SSD is huge.

We can also measure the multi-threaded version of Stan here,
which will require less memory.

We can also think about just buffering all the sample data,
which is almost always possible given the size models we're
dealing with, which makes the sampling fast, but adds a big
write step.  Speaking of which.


5.  How much wait time is there at the end? 

None in Stan.  But I seem to recall waiting eons for BUGS and
JAGS programs to actually be done once they'd stopped sampling.
I think this may be because they buffer all the data and then
write it all at once.  (That's a pretty big scaling bottleneck
if you want a lot of samples.)


5.  How much peak memory is required?

Perhaps this can be broken out by stages -- for instance,
Stan might need more memory to compile than run a model
in some cases and the other way around in other cases.  JAGS
might need a lot of memory to analyze and read the model
which can then be freed.  

