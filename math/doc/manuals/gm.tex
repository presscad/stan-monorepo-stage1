\documentclass[10pt]{report}

% ------ if Lucida not available --------------
% \usepackage{times}
% \usepackage{amssymb}
% ----- if Lucida availalable------------------
\usepackage[%romanfamily=times,
            scale=0.875,
            stdmathitalics=true,
            stdmathdigits=true]{lucimatx}
% -------------- end if------------------------

\usepackage{amsmath}

\usepackage{xspace}
\usepackage{fancyvrb}
\usepackage{titlesec}

\usepackage{url}

\titleformat{\chapter}[hang]{\bfseries\huge}{\thechapter.}{1.5pc}{}{}
%\titlespacing{\chapter}{0pt}{-12pt}{18pt}{}
%
\titleformat{\section}{\bfseries\large}{\thesection.}{1em}{}
%\titlespacing{\section}{0pt}{12pt}{6pt}
%
\titleformat{\subsection}{\it}{}{0em}{}
%\titlespacing{\subsection}{-1em}{12pt}{6pt}

\newcommand{\Stan}{Stan\xspace}
\newcommand{\stanc}{{\ttfamily stanc}\xspace}
\newcommand*{\Cpp}{C\raise.2ex\hbox{\footnotesize ++}\xspace} %\ensuremath{++}
\newcommand{\clang}{{\ttfamily clang\raise.2ex\hbox{\footnotesize ++}}\xspace} 
\newcommand{\gpp}{{\ttfamily g\raise.2ex\hbox{\footnotesize ++}}\xspace} 

\newcommand{\acronym}[1]{{\sc #1}\xspace}

\newcommand{\ASCII}{\acronym{ascii}}
\newcommand{\BNF}{\acronym{bnf}}
\newcommand{\MATLAB}{\acronym{matlab}}
\newcommand{\R}{\acronym{r}}
\newcommand{\SPLUS}{\acronym{s}}
\newcommand{\BUGS}{\acronym{bugs}}
\newcommand{\JAGS}{\acronym{jags}}
\newcommand{\MCMC}{\acronym{mcmc}}
\newcommand{\HMC}{\acronym{hmc}}
\newcommand{\NUTS}{\acronym{nuts}}
\newcommand{\MSVC}{\acronym{msvc}}
\newcommand{\LKJ}{\acronym{lkj}}
\newcommand{\CPC}{\acronym{cpc}}

\newcommand{\code}[1]{{\tt #1}}
\newcommand{\mycaption}[2]{\caption{{\it #2}\label{#1.figure}}}

\newcommand{\refappendix}[1]{Appendix~\ref{#1.appendix}}
\newcommand{\refpart}[1]{Part~\ref{#1.part}}
\newcommand{\refchapter}[1]{Chapter~\ref{#1.chapter}}
\newcommand{\refsection}[1]{Section~\ref{#1.section}}
\newcommand{\reffigure}[1]{Figure~\ref{#1.figure}}

\newcommand{\fitem}[4]{\item[{\tt #1 {\bfseries #2}(#3)}]\mbox{ } \\[4pt] #4}
\newcommand{\farg}[1]{{\tt\slshape #1}}

\newcommand{\cmdflag}[3]{\item[\tt {-}-#1] \mbox{ } \\ #2 \\ \hspace*{24pt}(#3)}
\newcommand{\cmdarg}[4]{\item[\tt {-}-#1={\slshape <#2>}] \mbox{ } \\ #3 \\ \hspace*{24pt}(#4)}

\newcommand{\samp}{{\lower.78ex\hbox{\texttt{\char`\~}}}}%
%{{\lower1.1ex\hbox{\Large\texttt{\char`\~}}}}

\setcounter{tocdepth}{0}

\title{\Huge\bf \Stan Modeling Language}
\author{\Stan's Development Team}
\date{\vspace*{36pt} Version 1.0 \\[4pt] {\small \today}} % \footnotesize \today}

\begin{document}

\maketitle

\begin{abstract}
  \Stan is a general-purpose probabilistic modeling framework designed
  to support full Bayesian inference.  This document describes \Stan's
  modeling language for specifying the joint probability of observed
  data and unobserved parameters.  \Stan's compiler parses model
  specifications and generates \Cpp code.  \Stan's modeling language
  is based on \BUGS and \JAGS, and like them, allows users to develop,
  fit, and evaluate Bayesian models without knowing \Cpp.

  \Stan performs inference by Markov chain Monte Carlo (\MCMC)
  sampling of parameter values from the posterior distribution of
  parameters given the observed data.  \Stan employs the no-U-turn
  sampler (\NUTS), an adaptive form of Hamiltonian Monte Carlo (\HMC)
  that alleviates the need for user tuning of \HMC's rather sensitive
  parameters.  By making effective use of the gradient of the log
  posterior, \HMC converges and explores the parameter distribution
  faster than Gibbs sampling or random-walk Metropolis-Hastings.  The
  improved sampling algorithm and more compact and efficient compiled
  code allows \Stan to operate on data of larger scales and models of
  more complex structure than \BUGS or \JAGS.
\end{abstract}

\tableofcontents

\part{Introduction}

\chapter{What is \Stan?}

This document is a reference manual and getting started guide for
using \Stan's probabilistic modeling language.  After describing the
overall system in this introduction and providing a hands-on
quick-start guide in the following chapter, the remainder of the
document is devoted to fully documenting the behavior of
Stan's modeling language.

\Stan's modeling language and its execution behavior are similar to
that of its progenitors, \BUGS and \JAGS.  It differs in many
particulars of the modeling language, which is more like an
impertative programming language than the declarative specifications
of \BUGS and \JAGS.  For instance, \Stan statements are executed in
the order they are written in model specifications and local variables
may be reassigned as in a procedural programming language.
Furthermore, variables must be declared before they are used.


\section{\Stan's Modeling Language}

\noindent
\Stan's modeling language allows users to code a Bayesian model
specifying a joint probability function
\[
p(y,\theta),
\]
where 
\begin{itemize}
\item
  $y$ is a vector of known values, such as 
  constants, hyperparameters, and modeled data, and
\item
 $\theta$ is a vector of unknown values, such as estimated parameters,
  missing data, and simulated values.
\end{itemize}
%
To simplify terminology, $y$ will be called the data vector and
$\theta$ the parameter vector.  The probability function $p(y,\theta)$
need only be specified up to a multiplicative constant with respect to
any fixed data vector $y$.  This ensures proportionality of the
posterior to the specified joint probability,
\[
p(\theta|y) \propto p(y,\theta) = p(\theta|y) \, p(y).
\]

Stan's language is more imperative than its declarative 
predecessors, \BUGS and \JAGS.  Statements are executed in the order 
they are specified and variables and expressions are strongly typed 
and declared as data or parameters in the model rather than by a 
calling function.  Stan also supports a broader range of arithmetic, 
matrix, and linear algebra operations than \BUGS or \JAGS.  Users may 
manipulate log probability functions directly and are not required 
to use proper priors.

\section{\Stan's Compiler}

\Stan's compiler, \stanc, reads a user program in \Stan's modeling
language and generates a \Cpp class implementing the model specified
by that program.  \Stan automatically applies a multivariate transform
(and its Jacobian determinant) to free any constrained parameters,
such as deviations (constrained to be positive), simplexes (a vector
constrained to be positive and to sum to 1), and covariance matrices
(positive definiteness).  The result is an unconstrained sampling (or
optimization) problem from the perspective of the sampler.  From the
user's perspective, this transform happens behind the scenes, driven
by the types declared for each of the parameters.

The generated \Cpp class can be plugged into Stan's continuous and
discrete samplers to read the data $y$ and then draw a sequence of
sample parameter vectors $\theta^{(m)}$ according to the posterior,
\[
p(\theta|y) = \frac{p(y,\theta)}{p(y)} \propto p(y,\theta).
\]
The resulting samples may be used for full Bayesian inference, much of
which can be carried out within Stan.

\section{\Stan's Samplers}

For continuous variables, Stan uses Hamiltonian Monte Carlo (\HMC)
sampling. \HMC is a Markov chain Monte Carlo (\MCMC) method based on
simulating the Hamiltonian dynamics of a fictional physical system in
which the parameter vector $\theta$ represents the position of a
particle in $K$-dimensional space and potential energy is defined to
be the negative (unnormalized) log probability.  Each sample in the
Markov chain is generated by starting at the last sample, applying a
random momentum to determine initial kinetic energy, then simulating
the path of the particle in the field.  Standard \HMC runs the
simulation for a fixed number of discrete steps of a fixed step size
and uses a Metropolis adjustment to ensure detailed balance of the
resulting Markovian system.  This adjustment treats the momentum term
of the Hamiltonian as an auxiliary variable, and the only reason for
rejecting a sample will be discretization error in computing the
Hamiltonian.

\HMC treats the position of a particle, 
log probability as a negative potential
energy function, then samples by adding random kinetic energy and
simulating the 

In addition to basic \HMC, Stan implements an adaptive
version of \HMC, the No-U-Turn Sampler (\NUTS).  \NUTS automatically
tunes step sizes and a diagonal mass matrix during warmup and then
adapts the number of leapfrog integration steps during sampling.
Stan is expressive enough to allow most discrete variables to be
marginalized out.  For the remaining discrete parameters, Stan uses
Gibbs sampling if there are only a few outcomes and adaptive slice
sampling otherwise.


\chapter{Getting Started}

This chapter is designed to help users get acquainted with the overall
design of the \Stan language and calling \Stan from the command line.
For installation information, see \refappendix{install}.
Later chapters are devoted to expanding on the material in this
chapter with full reference documentation.


\section{A Minimal Program}

Stan is distributed with several working models.  The simplest of
these is found in the following location relative to the top-level
distribution.
%
\begin{quote}
\begin{Verbatim}
src/models/basic_distributions/normal.stan
\end{Verbatim}
\end{quote}
%
The contents of this file are as follows.
%
\begin{quote}
\begin{Verbatim}
parameters {
  real y;
}
model {
  y ~ normal(0,1);
}
\end{Verbatim}
\end{quote}
%
The model's single parameter \code{y} is declared to take real values.
The probability model specifies that \code{y} has a normal
distribution with location 0 and scale 1.  Basically, this model will
sample a single unit normal variate.  

\section{Whitespace and Semicolons}

In Stan, every variable declaration and atomic statement must be
terminated by a semicolon (\code{;}).  This is the convention followed
by programming languages such as \Cpp.  It is not the convention
followed by the statistical languages \R, \BUGS, or \JAGS.

The reason for the \Cpp convention is to ensure that differences in
whitespace are not meaningful.  In \R, \BUGS, and \JAGS, the following
is a complete, legal statement.
%
\begin{quote}
\begin{Verbatim}
a <- b +
     c
\end{Verbatim}
\end{quote}
%
In contrast, the usual way of typesetting mathematics and laying out
code in programming languages, with the operator continuing the
expression beginning a new line, is invalid.
%
\begin{quote}
\begin{Verbatim}
a <- b
     + c
\end{Verbatim}
\end{quote}
%
The only difference is in the kind of whitespace between \code{b} and
\code{+} and between \code{+} and \code{c}.  In \Stan, there is no
whitespace-dependent behavior.  Neither of these is a complete
statement, whereas either one terminated with a semicolon is.  The
second form is recommended for \Cpp and \Stan.


\section{Compiling  with {\tt\bfseries stanc}}

Starting at Stan's home directory, written here as {\tt \$stan},
the model may be compiled by the Stan compiler, \stanc, into \Cpp code
as follows.
%
\begin{quote}
\begin{Verbatim}[fontshape=sl]
> cd $stan
> stanc src/models/basic_distributions/normal.stan
\end{Verbatim}
%
\begin{Verbatim}
Model name=anon_model
Input file=src/models/basic_distributions/normal.stan
Output file=anon_model.cpp
\end{Verbatim}
\end{quote}
%
The output indicates the name of the model, here the default value
\code{anon\_model}, the input file from which the Stan program is
read, here \code{normal.stan}, and the output file to which the
generated \Cpp code is written, here \code{anon\_model.cpp}.  See
\refchapter{stanc} for more documentation on the \stanc compiler.

\section{Compiling the Generated Code}

The file generated by \stanc must next be compiled with a \Cpp
compiler by linking to \Stan's source and library directories using
the {\tt -I} option of the compiler.  The following example 
uses the \clang compiler for \Cpp.
%
\begin{quote}
\begin{Verbatim}[fontshape=sl]
> clang++ -I src -I lib anon_model.cpp 
\end{Verbatim}
\end{quote}
%
This command invokes the \clang compiler for \Cpp to create a
platform-specific executable in the default location, which is {\tt
  a.out} by convention.  If all goes well, as above, there is no
output to the console.  More information about compiling the \Cpp code
generated by Stan may be found in \refchapter{compiling-cpp}.
Installation information for \Cpp compilers may be found in
\refappendix{install}.

\section{Running the Sampler}

The executable resulting from compiling the generated \Cpp may be run
as follows.
%
\begin{quote}
\begin{Verbatim}[fontshape=sl]
> ./a.out
\end{Verbatim}
%
\begin{Verbatim}
STAN SAMPLING COMMAND
data = 
init = random initialization
samples = samples.csv
append_samples = 0
seed = 1331941513 (randomly generated)
chain_id=1 (default)
iter = 2000
warmup = 1000
thin = 1
leapfrog_steps = -1
max_treedepth = 10
epsilon = -1
epsilon_pm = 0
epsilon_adapt_off = 0
delta = 0.5
gamma = 0.05

Iteration: 2000 / 2000 [100%]  (Sampling)
\end{Verbatim}
\end{quote}
%
The program indicates to the standard output that the samples are
written to \code{samples.csv}.  The first few lines of this file
are comments about aspects of the run.
%
\begin{quote}
\begin{Verbatim}[fontshape=sl]
> cat samples.csv
\end{Verbatim}
\begin{Verbatim}
# Samples Generated by Stan
#
# stan_version_major=alpha
# stan_version_minor=0
# data=
# init=random initialization
# append_samples=0
# seed=1331941796
# chain_id=1
# iter=2000
# warmup=1000
# thin=1
# leapfrog_steps=-1
# max_treedepth=10
# epsilon=-1
# epsilon_pm=0
# delta=0.5
# gamma=0.05
...
\end{Verbatim}
\end{quote}
%
The ellipses notation, {\tt ...}, indicates that the output continues
beyond what's shown.  Here, what follows is the data in standard
comma-separate value ({\sc csv}) notation.
%
\begin{quote}
\begin{Verbatim}
...
lp__,treedepth__,y
-0.0126699,1,0.159185
-0.222796,1,-0.667527
-0.222796,1,-0.667527
-0.404457,1,-0.899397
...
\end{Verbatim}
\end{quote}
%
The first line consists of a header indicating the names of the
variables on the lines to follow, and each following line indicates a
single sampled value of the parameters.  The first column is reserved
for the (unnormalized) log probability (density) of the parameters,
with name {\tt lp\_\_} (the underscores are to prevent name conflicts
with user-defined model parameters).  The next values are for
reporting the behavior of the sampler.  In this case, the \NUTS
sampler was used, so there is a report of the depth of tree it
explored, with variable name {\tt treedepth\_\_}.  The remaining
values are parameters.  Here, the model has only one parameter, {\tt
  y}.  The first sampled value for {\tt y} is 0.159185, the second is
-0.667527, and so on.  

Note that the second sampled value is repeated.  This is not a bug.
Rather, it is the behavior to expect from a sampler using a Metropolis
acceptance step for proposals, as Stan's samplers \HMC and \NUTS do.

\section{Data}

\Stan allows data to be specified in programs, used in models, and
read into compiled \Stan programs. This section provides an example of
coding and running a \Stan program with data stored in a file in the
\SPLUS/\R dump format.

The Stan program in 
\begin{quote}
\begin{Verbatim}
src/models/basic_estimators/bernoulli.stan
\end{Verbatim}
\end{quote}
can be used to estimate a Bernoulli parameter \code{theta} from
\code{N} binary observations.  The file contains the following code.
%
\begin{quote}
\begin{Verbatim}
data {
  int(0,) N;
  int(0,1) y[N];
}
parameters {
  real(0,1) theta;
}
model {
  theta ~ beta(1,1);
  for (n in 1:N)
    y[n] ~ bernoulli(theta);
}
\end{Verbatim}
\end{quote}
%
This program declares two data variables in its \code{data} block.
The first data variable, \code{N}, is an integer encoding the number
of observations.  The declaration \code{int(0,)} indicates that
\code{N} must take on non-negative values.  The second data variable,
\code{y}, is declared as \code{y[N]}, specifying that it is an array
of \code{N} values.  Each of these values has the declared type,
\code{int(0,1)}, an integer between 0 and 1 inclusive, i.e., a binary
value.  The \code{N} individual binary values in the array \code{y}
are accessed using standard array notation, indexing from 1, as \code{y[1]},
\code{y[2]}, ..., \code{y[N]}.

The \code{parametes} block declares a single parameter, \code{theta}.
Its type is given as \code{real(0,1)}, meaning it takes on continuous
values between 0 and 1 inclusive.  The constraint is necessary in
order to ensure that \code{theta} takes on a legal value as the
success parameter in the Bernoulli distribution in which it is used in
the \code{model} block of the program.

The \code{model} block consists of a for-loop for the data.   The loop is
specified so that the body is executed for values of \code{n} between
\code{1} and \code{N} inclusive.  The body here is a sampling
statement specifying that the variable \code{y[n]} is modeled as
having a Bernoulli distribution with parameter \code{theta}.  

A sample data file for this program can be found in the file
\code{bernoulli.Rdata} in the same directory.  This data file has
the following contents.
%
\begin{quote}
\begin{Verbatim}
N <- 10
y <- c(0,1,0,0,0,0,0,0,0,1)
\end{Verbatim}
\end{quote}
%
A data file must contain appropriate values for all of the data
variables declared in the \Stan program's \code{data} block.  Here there
is a non-negative integer value for \code{N} and an array of length
\code{N} (i.e., 10) integer values between 0 and 1 inclusive.  The
array is coded using the \SPLUS sequence notation \code{c(...)}.
The dump format supported by \Stan is documented in \refchapter{dump}.

The program is compiled by \stanc and the \Cpp compiler in the same
way.  This time, the output model gets an explicitly specified name.
%
%
\begin{quote}
\begin{Verbatim}[fontshape=sl]
> stanc --name=bern src/models/basic_estimators/bernoulli.stan 
\end{Verbatim}
\begin{Verbatim}
Model name=bern
Input file=src/models/basic_estimators/bernoulli.stan
Output file=bern.cpp
\end{Verbatim}
\end{quote}
%
As before, the \Cpp compiler needs to be given the name of
generated file.
%
\begin{quote}
\begin{Verbatim}[fontshape=sl]
> clang++ -O3 -I src -I lib -o bern bern.cpp
\end{Verbatim}
\end{quote}
%
There are two new compiler options here.  The option \code{-O3} sets
optimization to level 3, which generates much faster executable
code at the expense of slower compilation.  The name of the
executable is also specified, using the option \code{-o~bern}.  Now
the code may be executed by calling its executable with the data file
specified. 
%
\begin{quote}
\begin{Verbatim}[fontshape=sl]
> ./bern --data=src/models/basic_estimators/bernoulli.Rdata
\end{Verbatim}
\end{quote}



\section{Proper and Improper Priors}

The model in the previous section does not contain a sampling
statement for \code{theta}.  The default behavior is to give
\code{theta} a uniform prior.  In this case, a uniform prior is proper
because \code{theta} is bounded to a finite interval.  Improper priors
are also allowed in \Stan programs; they arise from unconstrained
parameters without sampling statements.  The uniform prior could have
also been added explicitly by adding the following statement to the
\code{model} block of the program.
%
\begin{quote}
\begin{Verbatim} 
theta ~ uniform(0,1);
\end{Verbatim}
\end{quote}
% 
A third way to specify that \code{theta} has a uniform distribution
between 0 and 1 is with the beta distribution.
%
\begin{quote}
\begin{Verbatim}
theta ~ beta(1,1);
\end{Verbatim}
\end{quote}
%
The beta distribution is conjugate to the Bernoulli, but \Stan (at
least as of yet) does not make use of this information.  On the other hand,
these three approaches, no prior, uniform prior, and beta prior,
are equally efficient in \Stan's sampler, because their uniformity
can be determined at compile time and thus computations related to
them eliminated.  There is further discussion of \Stan optimization
in \refchapter{optimization}


\part{Commands and Data Formats}


\chapter{Compiling Stan Programs 
\\ to C++ Programs}\label{stanc.chapter}

Preparing a \Stan program to be run involves two compilation steps,
%
\begin{enumerate}
\item compiling the \Stan program to \Cpp, and
\item compiling the resulting \Cpp to an executable.
\end{enumerate}
%
This chapter discusses the first step; the second step is discussed in
\refchapter{compiling-cpp}.

\section{The \stanc Compiler}

The \stanc compiler converts \Stan programs to \Cpp programs.  

The first thing it does is parse the \Stan program.  If the parser is
successful, it then generates \Cpp code.  If the parser fails, it will
provide an error message indicating where and why the error occurred.

The following example illustrates a fully qualified call to \stanc.
%
\begin{verbatim}
> stanc --name=binary_normal --o=binorm.cpp binormal.stan 
\end{verbatim}
%
This call specifies the name of the model, here {\tt binary\_normal}.
This will determine the name of the class implementing the model in
the \Cpp code.  The \Cpp code implementing the class is written to
\code{binorm.cpp}.  The final argument, \code{binormal.stan}, is
the file from which to read the \Stan program.


\section{Command-Line Options}

\begin{description}
%
\item[\tt {-}-help] 
\mbox{ } \\ 
Displays the manual page for \stanc.  If this option is selected,
nothing else is done.
%
\item[\tt {-}-version]
\mbox{ } \\ 
Prints the version of \stanc.  This is useful for bug reporting
and asking for help on the mailing lists.
%
\item[\tt {-}-name={\slshape class\_name}]
\mbox{ } \\ 
Specify the name of the class used for the implementation of the
\Stan model in the generated \Cpp code.  
\\[6pt]
Default: {\tt {\slshape class\_name = anon\_model}}
%
\item[\tt {-}-o={\slshape cpp\_file\_name}]
\mbox{ } \\ 
Specify the name of the file into which the generated \Cpp is written.
\\[6pt]
Default: {\tt {\slshape cpp\_file\_name} = {\slshape class\_name}.cpp}
%
\end{description}





\chapter{Compiling C++ Programs}\label{compiling-cpp.chapter}

\Stan has been developed using two portable, open-source compilers,
\gpp and \clang, which run under Windows, Macintosh, and Unix/Linux.
\Stan has also been compiled using \MSVC, a Windows-specific compiler
from Microsoft.

\section{Overview}

This section provides a complete example based on the \clang compiler
using optimizations; see the rest of the chapter for other compiler
options.

Suppose the \Cpp program for the model produced by \Stan resides in a
file called \code{my\_model.cpp} in the current working directory.
The following command will produce an executable in the file
\code{my\_model} in the current working directory.
%
\begin{quote}
\begin{Verbatim}
> clang++ -I $stan/src -I $stan/lib my_model.cpp -o my_model
\end{Verbatim}
\end{quote}
%
In the command, \code{\$stan} is used to denote the path to the
top-level \Stan directory, which contains the \Cpp source code of the
\Stan library itself (in \code{\$stan/src}) as well as the libraries
on which it depends (in \code{\$stan/lib}).

\section{Which Compiler?}

It has been our experience that \clang is much faster to
compile at all optimization levels than \gpp, but that the code
generated by \gpp is slightly faster to execute.

\section{What the Compiler Does}

A \Cpp compiler like \gpp or \clang actually performs several
lower-level operations in sequence,
% 
\begin{enumerate}
\item
parsing the input \Cpp source file(s), 
\item 
generating relocatable object code, and
\item 
linking the relocatable object code into executable code.
\end{enumerate}
%
These stages may be called separately, though the examples in
this manual perform them in a single call.


\section{Including Library Code}

\Stan is written as a set of header-only libraries.  This simplifies
writing code that uses Stan.  The only thing that needs to be done
is to include the relevant libraries.  

The compiler command-line option to include a
header-only library is 
%
\begin{quote}
\code{-I {\slshape path-to-library}}.
\end{quote}
%
The path to the library must be such that any \code{\#include}
statements within the \Cpp source files be resolvable starting from
the path to the library.  

The header-only library code for \Stan itself is located in the
subdirectory \code{src/} of the top-level \Stan directory.  To allow
programs to use the \Stan library, the compiler needs to be given the
option 
%
\begin{quote}
\code{-I {\slshape stan}/src} 
\end{quote}
%
where \code{\slshape stan} is the
path to the top-level Stan directory.  If the compiler is called from the
top-level Stan directory, it suffices to use \code{-I src}, as in the
examples in the first chapter.

\Stan depends on two open-source libraries,
%
\begin{enumerate}
\item Boost general purpose \Cpp libraries, and 
\item Eigen matrix and linear algebra \Cpp libraries
\end{enumerate}
%
These are both distributed along with \Stan in the directory
\code{{\slshape stan}/lib/}, where again \code{\slshape stan} is the
top-level directory of the \Stan distribution.  Both libraries take
include paths starting under \code{lib/}.  For most uses of \Stan, it
is also necessary to include an explicit compiler option to include
Eigen and Boost,
%
\begin{quote}
\code{-I {\slshape stan}/lib}
\end{quote}
%
with \code{\slshape stan} being the location of the top-level \Stan
directory.  Thus calling \Stan typically requires all three of \Stan,
Boost, and Eigen to be included, which is accomplished with
%
\begin{quote}
\code{-I {\slshape stan}/lib -I {\slshape stan}/src}
\end{quote}
%
where \code{\slshape stan} is the path to the top-level \Stan directory.


\section{Compiler Optimization}

Stan was written with an optimizing compiler in mind.  For
that reason, it runs as much as an order of magnitude or more
faster with optimization turned on.  

For development, we recommend optimization level 0, whereas for
sampling, we recommend optimization level 3.  These are controlled
through the compiler option \code{-O} (capital letter `O').  To
generate efficient code, use
%
\begin{quote}
\code{-O3}
\end{quote}
%
where the first character is the capital letter `O'.
For faster compile time but less efficient code, use
%
\begin{quote}
\code{-O0}
\end{quote}
%
where the first character is the capital letter `O' and
the second character is the digit `0'.

\section{Executable Name}

If no name is provided for the executable, the default value of
\code{a.out} is used.  This executable will show up in the directory
from which the compiler was called.

To put the executable in a different location, the \code{-o {\slshape
    path-to-executable}} command may be used.  In an earlier example,
\code{-o bern} was used to write the executable to a file called
\code{bern}.  (In Windows, executables are suffixed with \code{.exe}.)



\chapter{Running a \Stan Program}\label{stan-cmd.chapter}

Once a \Stan program defining a model has been converted to a \Cpp
program for that model (see \refchapter{stanc}) and the resulting \Cpp
program compiled to a platform-specific executable (see
\refchapter{compiling-cpp}), the model is ready to be run.

\section{Simple Example}

Supposing the executable is in file \code{mymodel} and the data
is in file \code{mydata}, both in the current working directory.
Then the \Stan executable may be run using
%
\begin{quote}
\begin{Verbatim}
> mymodel --data=mydata
\end{Verbatim}
\end{quote}
%
This will read the data from file \code{mydata}, run the default
fully-adaptive \NUTS sampler for 2000 iterations, discard the first
1000 iterations, writing the remainder to the file \code{samples.csv}
in the current working directory.  A random number generation seed
will be generated from the system time automatically.

\section{Command-Line Options}

The executable \Stan program is highly configurable.  At the highest
level, it may be configured for type of sampler (basic \HMC or \NUTS,
with or without step size adaptation), it may be provided with
data, initializations, a file to which to send the output, random
number generation seeds, etc.  

The full set of options is as follows.  The next section provides
some typical use-case examples.
%
\begin{description}
\cmdflag{help}
{Display help information including the command call and
  options.}
{default = \code{false}}
%
\cmdarg{data}{file}
{Read data from specified dump formatted
  file}
{required if model declares data}
%
\cmdarg{init}{file}
{Use initial values from specified file or zero
  values if <file>=0}
{default is random initialization}
%
\cmdarg{samples}{file}
{File into which samples are written}
{default = \code{samples.csv}}
%
\cmdflag{append\_samples}
{Append samples to existing file if it exists}
{does not write header in append mode}
%
\cmdarg{seed}{int}
{Random number generation seed}
{default is to randomly generate from time}
%
\cmdarg{chain\_id}{int}
{Markov chain identifier}
{default = \code{1}}
%
\cmdarg{iter}{+int}
{Total number of iterations, including warmup}
{default = \code{2000}}
%
\cmdarg{warmup}{+int}
{Discard the specified number of initial samples}
{default = \code{iter / 2}}
%
\cmdarg{thin}{+int}
{Period between saved samples after warm up}
{default = \code{max(1, floor(iter - warmup) / 1000)}}
%
\cmdarg{refresh}{+int}
{Period between samples updating progress report print}
{default = \code{max(1, iter / 200)}}
%
\cmdarg{leapfrog\_steps}{int}
{Number of leapfrog steps; \code{-1} for No-U-Turn adaptation}
{default = \code{-1}}
%
\cmdarg{max\_treedepth}{int}
{Limit \NUTS leapfrog steps to \code{pow(2,max\_tree\_depth)}; \code{-1} for no limit}
{default = \code{10}}
%
\cmdarg{epsilon}{float}
{Initial value for step size, or \code{-1} to set automatically}
{default = \code{-1}}
%
\cmdarg{epsilon}{[0,1]}
{Sample epsilon \code{+/- epsilon * epsilon\_pm}}
{default = \code{0.0}}
%
\cmdflag{epsilon\_adapt\_off}
{Turn off step size adaptation}
{default = \code{false}, i.e., step size adaptation is on by default}
%
\cmdarg{delta}{+float}
{Initial step size for step-size adaptation}
{default = \code{0.5}}
%
\cmdarg{gamma}{+float}
{Gamma parameter for dual averaging step-size adaptation}
{default = \code{0.05}}
%
\cmdflag{test\_grad}
{Test gradient calculations using finite differences; if this option
  is chosen, only the gradient tests are done.}
{default = \code{false}, i.e., no gradient tests}
%
\end{description}









\chapter{Dump Data Format}\label{dump.chapter}

For representing structured data in files, \Stan uses the dump format
introduced in \SPLUS and used in \R and \JAGS (and in \BUGS, but with
a different ordering).   A dump file is structured as a sequence of
variable definitions.  Each variable is defined in terms of its
dimensionality and its values.   There are three kinds of variable
declarations, one for scalars, one for sequences, and one for general
arrays.

\section{Scalar Variables}

A simple scalar value can be thought of as having an empty list of
dimensions.  Its declaration in the dump format follows the \SPLUS
assignment syntax.  For example, the following would constitute a
valid dump file defining a single scalar variable \code{y} with value
17.2.
%
\begin{quote}
\begin{Verbatim}
y <- 
17.2
\end{Verbatim}
\end{quote}
%
A scalar value is just a zero-dimensional array value.

\section{Sequence Variables}

One-dimensional arrays may be specified directly using the \SPLUS
sequence notation.  The following example defines an integer-value and
a real-valued sequence.
%
\begin{quote}
\begin{Verbatim}
n <- c(1,2,3)
y <- c(2.0,3.0,9.7)
\end{Verbatim}
\end{quote}
%
It is possible to define an array without a declaration of
dimensionality because the reader just counts the number of entries to
determine the size of the array.

\section{Array Variables}

For more than one dimension, the dump format uses a dimensionality
specification.  For example,
%
\begin{quote}
\begin{verbatim}
y <- structure(c(1,2,3,4,5,6), .Dim = c(2,3))
\end{verbatim}
\end{quote}
%
This defines a $2 \times 3$ array.  Data is stored in column-major
order, meaning the values for \code{y} will be as follows.
%
\begin{quote}
\begin{Verbatim}
y[1,1] = 1     y[2,1] = 3     y[3,1] = 5    
y[2,1] = 2     y[2,2] = 4     y[3,2] = 6
\end{Verbatim}
\end{quote}
%
The \code{structure} keyword just wraps a sequence of values and a
dimensionality declaration, which is itself just a sequence of
non-negative integer values.  The product of the dimensions must equal
the length of the array.


\section{Integer- and Real-Valued Variables}

There is no declaration in a dump file that distinguishes integer
versus real values.  If a value in a dump file's definition of a
variable contains a decimal point, \Stan assumes that the values are
real.  If there are no decimal points in a variable's defined value, 
the value may be assigned to variables declared as integer or real
in \Stan.

The following dump file declares an integer value for \code{y}.
%
\begin{quote}
\begin{Verbatim} 
y <- 
2
\end{Verbatim}
\end{quote}
% 
This definition can be used for a \Stan variable \code{y} declared as
\code{real} or as \code{int}.  Assigning an integer value to a real
variable automatically promotes the integer value to a real value.

The following dump file provides a real value for \code{y}.
%
\begin{quote}
\begin{Verbatim}
y <-
2.0
\end{Verbatim}
\end{quote}
%
Even though this is a round value, the occurrence of the decimal
point in the value, \code{2.0}, causes \Stan to infer that \code{y} is
real valued.  This dump file may only be used for variables \code{y}
delcared as real in \Stan.


\section{Quoted Variable Names}

In order to support \JAGS data file, variables may be double quoted.
For instance, the following definition is legal in a dump file.
%
\begin{quote}
\begin{Verbatim}
"y" <-
c(1,2,3)
\end{Verbatim}
\end{quote}

\section{Line Breaks}

The line breaks in a dump file are required to be consistent with
the way \R reads in data.  Both of the following declarations are
legal.
%
\begin{quote}
\begin{Verbatim}
y <- 2
y <-
3
\end{Verbatim}
\end{quote}
%
Following its roots in \R, breaking before the assignment arrow is not
allowed.
%
\begin{quote}
\begin{Verbatim}
y
<- 2  # Syntax Error
\end{Verbatim}
\end{quote}

Lines may also be broken in the middle of sequences declared
using the \code{c(...)} notation., as well as between the comma
following a sequence definition and the dimensionality declaration.
For example, the following declaration of a $1 \times 2 \times 3$
array is valid.
%
\begin{quote}
\begin{Verbatim}
y <-
structure(c(1,2,3,
4,5,6,7,8,9,10,11,
12), .Dim = c(2,3,
4))
\end{Verbatim}
\end{quote}

\section{General R Sequence Syntax}

Sometimes, \R will use shorthand for its output. For example,
starting \R,

\begin{quote}
\begin{Verbatim}[fontshape=sl]
> R
\end{Verbatim}
\end{quote}
%
and then within \R, executing the following commands,

\begin{quote}
\begin{Verbatim}[fontshape=sl]
R> e <- matrix(c(1,2,3,4,5,6),nrow=2,ncol=3)
R> dump("e")
\end{Verbatim}
\end{quote}
%
leads to a \code{dumpdata.R} file being created with
the following contents.
%
\begin{quote}
\begin{Verbatim}
e <-
structure(c(1, 2, 3, 4, 5, 6), .Dim = 2:3)
\end{Verbatim}
\end{quote}
%
\R has used the fact that it allows a contiguous
sequence to be specified with its start and end point
using the notation \code{2:3}.  \Stan cannot currently
parse this format of input.  

Alternatively, \R is prone to include long-integer specifiers.
For instance, a $2 \times 2$ matrix is dumped as follows.
%
\begin{quote}
\begin{Verbatim}
f <-
structure(c(1, 2, 3, 4), .Dim = c(2L, 2L))
\end{Verbatim}
\end{quote}
%
Here the dimensions are defined to be \code{c(2L,~2L)}.  \Stan 
always treats these dimesions as \code{L}.







\part{Modeling Language Reference}

\chapter{Data Types \\ and Variable Declarations}\label{data-types.chapter}

This chapter covers the data types that values may have in \Stan.
Every variable used in a \Stan program must have a declared data type.
Only values of that type will be assignable to the variable.  This
follows the convention of programming languages like \Cpp, not the
conventions of scripting languages like Python or statistical
languages such as \R or \BUGS.  The motivation for strong, static
typing is twofold.  First, it forces the programmer's intent to be
declared with the variable, making programs easier to comprehend and
hence debug and maintain.  Second, it catches programming errors
relative to that intent to be caught sooner (at compile time) rather
than later (at run time).  The \Stan compiler (see \refchapter{stanc})
will flag any type errors and indicate the offending expressions
quickly when the program is compiled.

\section{Overview of Data Types}

The primitive \Stan data types are \code{real} for continuous scalar
quantities and \code{int} for integer values.  The compound data
types include \code{vector} (of real values), \code{row\_vector} (of
real values), and \code{matrix} (of real values).

Integer or real types may be constrained with lower bounds, upper
bounds, or both.  There are two specialized vector data types,
\code{simplex} for simplices and \code{pos\_ordered} for positive,
ordered sequences of scalars.  There are two specialized matrix data
types, \code{corr\_matrix} and \code{cov\_matrix}, for correlation
matrices (symmetric, positive definite, unit diagonal) and covariance
matrices (symmetric, positive definite). 

\Stan supports arrays of arbitrary order of any of the basic data
types or constrained basic data types.  This includes
three-dimensional arrays of integers, one-dimensional arrays of
positive reals, four-dimensional arrays of simplexes, one-dimensional
arrays of row vectors, and so on.



\section{Primitive Numerical Data Types}

Unfortunately, the lovely mathematical abstraction of integers and
real numbers is only partially supported by finite-precision computer
arithmetic.  

\subsection{Integers}\label{int-data-type.section}

Stan uses 64-bit (8-byte) integers for all of its integer
representations.  The maximum value that can be represented
as an integer is $2^{63}-1$; the minimum value is $-(2^{63})$.

When integers overflow, their values wrap.  Thus it is up to
the \Stan programmer to make sure the integer values in their programs
stay in range.  In particular, every intermediate expression must have
an integer value that is in range.

\subsection{Reals}\label{real-data-type.section}

\Stan uses 64-bit (8-byte) floating point representations of real
numbers.  \Stan roughly%
%
\footnote{\Stan compiles integers to \code{long int} and reals to
  \code{double} types in \Cpp.  Precise details of rounding will depend
  on the compiler and hardware architecture on which the code is run.}
%
follows the {\sc ieee} 754 standard for floating-point computation.
The range of a 64-bit number is roughly $\pm 2^{1022}$, which is
slightly larger than $\pm 10^{307}$.  It is a good idea to stay well
away from such extreme values in \Stan models as they are prone to
cause overflow.

64-bit floating point representations have roughly 16 digits of
accuracy.  But when they are combined, the result often has less
accuracy.  In some cases, the difference in accuracy between two
operands and their result is large.  

There are three special real values used to represent (1) error
conditions, (2) positive infinity, and (3) negative infinity.  The
error value is referred to as ``not a number.''

\subsection{Promoting Integers to Reals}

\Stan automatically promotes integer values to real values if
necessary, but does not automatically demote real values to integers.
This will cause rounding errors for very large integers .

Real values are not demoted to integers.  For examples, real values
may only be assigned to real variables, but integer values may be
assigned to either integer variables or real variables.  What happens
interally is that the integer representation is converted to a
floating-point representation.  This operation is not free and is thus
best avoided if possible.


\section{Univariate Data Types and Variable Declarations}

All variables used in a \Stan program must have an explicitly declared
data type.  The form of a declaration includes the type and the name
of a variable.  This secton covers univariate types, the next section
vector and matrix types, and the following section array types.

\subsection{Unconstrained Integer}

Unconstrained integers are declared using the \code{int} keyword.
For example, the variable \code{N} is declared to be an integer using
%
\begin{quote}
\begin{Verbatim} 
int N;
\end{Verbatim}
\end{quote}
% 
As in this example, all variable declarations must end with semicolon.

\subsection{Constrained Integer}

Integer data types may be constrained to allow values only in a
specified interval by providing a lower bound, an upper bound, or
both.  For instance, to declare \code{N} to be a positive integer, use
%
\begin{quote}
\begin{Verbatim}
int(1,) N;
\end{Verbatim}
\end{quote}
%
This illustrates that the bounds are inclusive for integers.

To declare an integer variable \code{cond} to take only binary values,
that is 0 or 1, a lower and upper bound must be provided, as in
%
\begin{quote}
\begin{Verbatim} 
int(0,1) cond;
\end{Verbatim}
\end{quote}


\subsection{Unconstrained Real}

Unconstrained real variables are declared using the keyword
\code{real}.  For example,
%
\begin{quote}
\begin{Verbatim}
real theta;
\end{Verbatim}
\end{quote}
%
declares a real valued variable \code{theta}.

\subsection{Constrained Real}

Real variables may be bounded using the same syntax as integers.  In
theory (that is, with arbitrary-precision arithmetic), the bounds on
real values would be exclusive.  Unfortunately, finite-precision
arithmetic rounding errors will often lead to values on the
boundaries, so they are allowed in \Stan.
 
The variable \code{sigma} may be declared to be non-negative by
%
\begin{quote}
\begin{Verbatim}
real(0,) sigma;
\end{Verbatim}
\end{quote}
%
The variable \code{x} may be declared to be less than -1 by
%
\begin{quote}
\begin{Verbatim} 
real(,-1) x;
\end{Verbatim}
\end{quote}
% 
To ensure \code{rho} takes on values between -1 and 1, use
%
\begin{quote}
\begin{Verbatim}
real(-1,1) rho;
\end{Verbatim}
\end{quote}
%


\subsection{Expressions as Bounds}

Bounds for integer or real variables may be arbitrary expressions, the
only requirement being that they do not include non-data variables.
That is, any variable used in an expression declaring a bound must be
declared in the data block or the transformed data block.  For
example, it is acceptable to have the following
%
\begin{quote}
\begin{Verbatim}
data { 
 real lb;
}
parameters {
 real(lb,) phi;
}
\end{Verbatim}
\end{quote}
%
This declares a real-valued parameter \code{phi} to take values
greater than the value of the real-valued data variable \code{lb}.
Constraints may involve arbitrary expressions so long as the result is
of type integer and the only variables involved are data or
transformed data variables.  For instance,
\begin{quote}
\begin{Verbatim}
data { 
 int(1,) N;
 real y[N];
}
parameters {
 real(min(y),max(y)) phi;
}
\end{Verbatim}
\end{quote}
%
This declares a positive integer data variable \code{N}, an array \code{y} of
real-valued data of length \code{N}, and then a parameter ranging
between the minimum and maximum value of \code{y}.


\section{Vector and Matrix Data Types}

\subsection{Indexing}

Vectors and matrices, as well as arrays, are indexed starting from 1
in \Stan.  This follows the convention in statistics and linear
algebra as well as their implementations in the statistical software
packages \R, \MATLAB, \BUGS, and \JAGS.  General computer programming
languages, on the other hand, such as \Cpp and Python, index from 0.


\subsection{Unconstrained Vectors}

Vectors in \Stan are column vectors; see the next subsection for
information on row vectors.  Vectors are declared with a size (i.e., a
dimensionality).  For example, a 3-dimensional vector is declared with
the keyword \code{vector}, as in 
%
\begin{quote}
\begin{Verbatim}
vector(3) u;
\end{Verbatim}
\end{quote}
%

\subsection{Unit Simplices}

A unit simplex is a vector with non-negative values whose entries sum
to 1.  For instance, $(0.2,0.3,0.4,0.1)^{\top}$ is a unit 4-simplex.
Unit simplexes are most often used as parameters in categorical
or multinomial distributions, and they are also the sampled variate in
a Dirichlet distribution.  Simplices are declared with their full
dimensionality.  For instance, \code{theta} is declared to
be a unit $5$-simplex by
%
\begin{quote}
\begin{Verbatim} 
simplex(5) theta;
\end{Verbatim}
\end{quote}
% 

Unit simplices are implemented as vectors and may be assigned to other
vectors.  


\subsection{Positive, Ordered Vectors}

A positive ordered vector is a vector whose positive entries are
sorted in ascending order.  For instance, $(1.0,2.7,2.71)^{\top}$ is a
positive, ordered vector.  Positive ordered vectors are most often
employed as cut points in ordinal logistic regression models.  

The variable \code{c} is declared as an ordered 5-vector of positive
values by
%
\begin{quote}
\begin{Verbatim}
pos_ordered(5) c;
\end{Verbatim}
\end{quote}
%

After their declaration, positive, ordered vectors, like unit
simplices, may be assigned to other vectors and other vectors may be
assigned to them.  

\subsection{Unconstrained Row Vectors}

Row vectors are declared with the keyword \code{row\_vector}.
Like (column) vectors, they are declared with a size.  For example,
a 1093-dimensional row vector \code{u} would be declared as
%
\begin{quote}
\begin{Verbatim}
row_vector(1093) u;
\end{Verbatim}
\end{quote}
%

Row vectors may not be assigned to column vectors, nor may column
vectors be assigned to row vectors.  If assignments are required, they
may be done element-wise in a loop or by using the transpose operator.

\subsection{Unconstrained Matrices}

Matrices are declared with the keyword \code{matrix} along with a
number of rows and number of columns.  For example, 
%
\begin{quote}
\begin{Verbatim}  
matrix(3,3) A;  
matrix(M,N) B;
\end{Verbatim}
\end{quote}
%  
declares \code{A} to be a $3 \times 3$ matrix and \code{B} to be a $M
\times N$ matrix.  For the second declaration to be well formed, the
variables \code{M} and \code{N} must be declared as integers in either
the data or transformed data block.

\subsection{Correlation Matrices}

Matrix variables may be constrained to represent correlation matrices.
A matrix is a correlation matrix if it is positive definite (and hence
square and symmetric), has entries between -1 and 1, and has a unit
diagonal.  Because correlation matrices are square, they only need one
dimension declared.  For example,
%
\begin{quote}
\begin{Verbatim} 
corr_matrix(3) Sigma;
\end{Verbatim}
\end{quote}
% 
declares \code{Sigma} to be a $3 \times 3$ correlation matrix.

Correlation matrices may be assigned to other matrices, including
unconstrained matrices, if their dimensions match, and vice-versa.

\subsection{Covariance Matrices}

Matrix variables may be constrained to represent covariance matrices.
A matrix is a covariance matrix if it is positive definite (and hence
square and symmetric with positive diagonal entries).  Like
correlation matrices, covariance matrices only need a single dimension
in their declaration.  For instance,
%
\begin{quote}
\begin{Verbatim} 
cov_matrix(K) Omega;
\end{Verbatim}
\end{quote}
% 
declares \code{Omega} to be a $K \times K$ correlation matrix, where
$K$ is the value of the data variable \code{K}.

\subsection{Accessing Vector and Matrix Elements}

If \code{v} is a column vector or row vector, then \code{v[2]} is the
second element in the vector.  If \code{m} is a matrix, then
\code{m[2,3]} is the value in the second row and third column.

Providing a matrix with a single index returns the specified row.  For
instance, if \code{m} is a matrix, then \code{m[2]} is the second row.
This allows \Stan blocks such as
%
\begin{quote}
\begin{Verbatim} 
matrix(M,N) a;    
row_vector(N) v;    
real x;
...
v <- m[2];   
x <- v[3];   // x == m[2][3] == m[2,3]
\end{Verbatim}
\end{quote}
% 
The type of \code{m[2]} is \code{row\_vector} because it is the second
row of \code{m}.  Thus it is possible to write \code{m[2][3]} instead
of \code{m[2,3]} to access the third element in the second row.  When
given a choice, the form \code{m[2,3]} is preferred.%
%
\footnote{As of the beta version of \Stan version 1.0, the form
  \code{m[2,3]} is more efficient because it does not require the
  creation and use of an intermediate expression template for
  \code{m[2]}.  In later versions, explicit calls to \code{m[2][3]}
  may be optimized to be as efficient as \code{m[2,3]} by the \Stan
  compiler.}


\section{Array Data Types}

\Stan supports arrays of arbitrary dimension.  An array's elements may
be any of the basic data types, that is univariate integers,
univariate reals, vectors, row vectors matrices, including all of the
constrained forms.

\subsection{Declaring Array Variables}

Arrays are declared by enclosing the dimensions in square brackets
following the name of the variable.

The variable \code{n} is declared as an array of 5 integers by
%
\begin{quote}
\begin{Verbatim}  
int n[5];
\end{Verbatim}
\end{quote}
% 
A 2-dimensional array of real values with 3 rows and 4 columns is
delcared with
%
\begin{quote}
\begin{Verbatim}  
real a[3,4];
\end{Verbatim}
\end{quote}
% 
A 3-dimensional array \code{z} of positive reals with 5 rows, 4
columns, and 2 shelfs is declared by
%
\begin{quote}
\begin{Verbatim} 
real(0,) z[5,4,2];
\end{Verbatim}
\end{quote}
%

Arrays may also be declared to contain vectors.  For example,
%
\begin{quote}
\begin{Verbatim}  
vector(7) mu[3];
\end{Verbatim}
\end{quote}
% 
declares \code{mu} to be a 3-dimensional array of 7-vectors.  
Arrays may also contain matrices.  The example
%
\begin{quote}
\begin{Verbatim} 
matrix(7,2) mu[15,12];
\end{Verbatim}
\end{quote}
%
declares a $15 \times 12$-dimensional array of $7 \times 2$ matrices.
Any of the constrained types may also be used in arrays, as in the
declaration
%
\begin{quote}
\begin{Verbatim}  
cov_matrix(5) mu[2,3,4];
\end{Verbatim}
\end{quote}
% 
of a $2 \times 3 \times 4$ array of $5 \times 5$ covariance matrices.

\subsection{Accessing Array Elements and Subarrays}

If \code{x} is a 1-dimensional array of length 5, then \code{x[1]} is
the first element in the array and \code{x[5]} is the last.  For a $3
\times 4$ array \code{y} of 2-dimesions, \code{y[1,1]} is the first
element and \code{y[3,4]} the last element.  For a 3-dimensional
array \code{z}, the first element is \code{z[1,1,1]}, and so on.

Slices of arrays may be accessed by providing fewer than the full
number of indexes.  For example, suppose \code{y} is a 2-dimensional
array with 3 rows and 4 columns.  Then \code{y[3]} is 1-dimensional
array of length 4.  This means that \code{y[3][1]} may be used instead
of \code{y[3,1]} to access the value of the first column of the third
row of \code{y}.  The form \code{y[3,1]} is the preferred form.

Subarrays may be manipulated and assigned just like any other
variables.  Similar to the behavior of matrices, \Stan allows blocks
such as 
%
\begin{quote}
\begin{Verbatim} 
real w[9,10,11];
real x[10,11];
real y[11];
real z;
...
x <- w[5];
y <- x[4];  // y == w[5][4] == w[5,4]
z <- y[3];  // z == w[5][4][3] == w[5,4,3]
\end{Verbatim}
\end{quote}
%

\section{Types versus Sizes}

The size associated with a given variable is not part of its data
type.  The sizes may determined dynamically (at run time) and thus
cannot be type-checked statically.  

\subsection{Type Naming Notation}

In order to refer to data types, it is convenient to have a way to
refer to them.  The type naming notation outlined in this section is
not part of the \Stan programming language, but rather a convention
adopted in this document to enable a concise description of a type.

Because size information is not part of a data type, data
types will be written without size information.  For instance,
\code{real[]} is the type of one-dimensional array of reals and
\code{matrix} is the type of matrices.  The three-dimensional integer
array type is written as \code{int[,,]}, indicating the number slots
available for indexing.  Similarly, \code{vector[,]} is the type of a
two-dimensional array of vectors.





\chapter{Expressions}

An expression is the basic syntactic unit in a \Stan program that
denotes a value.  Every expression in a well-formed \Stan program has
a type that is determined statically (at compile time).  If an
otherwise well-formed program has an expression whose type cannot be
determined statically, the \Stan compiler (see \refchapter{stanc})
will report the location of the ill-formed expression.

This chapter covers the syntax, typing, and usage of the various forms
of expressions in \Stan. 

\section{Numeric Literals}

The simplest form of expression is a literal that denotes a primitive
numerical value.   

\subsection{Integer Literals}

A number written without a period is assigned the integer numeric type
\code{int}.

Integer literals are written in base 10 without any separators.
Integer literals may contain a single negative sign.  (The expression
\code{--1} is interpreted as the negation of the literal \code{-1}.)

The following list contains well-formed integer literals.
%
\begin{quote}
\code{0}, \ \code{1}, \ \code{-1}, \ \code{256}, 
\ \code{-127098}, \ \code{24567898765}
\end{quote}
%
Integer literals must have values that fall within the bounds for
integer values (\refsection{int-data-type}).

\subsection{Real Literals}

A number written with a period or with scientific notation is assigned
to a the continuous numeric type \code{real}.  Real literals are
written in base 10 with a period (\code{.}) as a separator.  Examples
of well-formed double literals include the following.
%
\begin{quote}
\code{0.0}, \ \code{1.0}, \ \code{3.14}, \ \code{-217.9387}, \ 
\code{2.7e3}, \ \code{-2E-5}
\end{quote}
%
The notation \code{e} or \code{E} followed by a positive or negative
integer denotes a power of 10 to multiply.  For instance \code{2.7e3}
denotes $2.7 \times 10^3$ and \code{-2E-5} denotes $-2 \times
10^{-5}$.


\section{Variables}

A variable by itself is a well-formed expression of the same type as
the variable.  Variables in \Stan consist of \ASCII strings containing
only the basic lower-case and upper-case Roman letters, digits, and
the underscore (\code{\_}) character.   Examples of legal variable
identifiers are as follows.
\begin{quote}
\code{a}, 
\ \code{a3}, 
\ \code{a\_3},
\ \code{Sigma}, 
\ \code{my\_cpp\_style\_variable},
\ \code{myCamelCaseVariable}
\end{quote}
%
Unlike in \R and \BUGS, variable identifiers in \Stan may not contain
a period character.

\subsection{Legal Characters}

The legal variable characters have the same \ASCII code points in the
range 0--127 as in Unicode.
%
\begin{center}
\begin{tabular}{cc}
Characters  & \ASCII (Unicode) Code Points
\\ \hline
\code{a -- z} & \code{{}~97 -- 122}
\\
\code{A -- Z} & \code{{}~65 -- {}~90}
\\
\code{0 -- 9} & \code{{}~48 -- {}~57}\
\\
\code{\_} & \code{95}
\end{tabular}
\end{center}
%
Although not the most expressive character set, \ASCII is the most
portable and least prone to corruption through improper character
encodings or decodings.

\section{Arithmetic and Matrix Expressions}

For integer and real-valued expression, \Stan supports the basic
binary arithmetic operations of addition (\code{+}), subtraction
(\code{-}), multiplication (\code{*}) and division (\code{/}) in the
usual ways.  \Stan also supports the unary operation of negation for
integer and real-valued expressions.  For example, assuming \code{n}
and \code{m} are integer variables and \code{x} and \code{y} real
variables, the following expressions are legal.
\begin{quote}
\code{3.0 + 0.14}, 
\ \ \code{-15},
\ \ \code{2 * 3 + 1}, 
\ \ \code{(x - y) / 2.0},
\\
\ \ \code{(n * (n + 1)) / 2},
\ \ \code{x / n}
\end{quote}
%
The negation, addition, subtraction, and multiplication operations are
extended to matrices, vectors, and row vectors.  The transpose
operation, written using an apostrophe (\code{'}) is also supported
for vectors, row vectors, and matrices.  Return types for matrix
operations are the smallest types that can be statically guaranteed to
contain the result.  The full set of allowable input types and
corresponding return types is detailed in
\refchapter{matrix-operations}.

For example, if \code{y} and \code{mu} are variables of type
\code{vector} and \code{Sigma} is a variable of type \code{matrix},
then
%
\begin{quote}
\code{(y - mu) * Sigma * (y - mu)'}
\end{quote}
%
is a well-formed expression of type \code{real}.  The type of the
complete expression is inferred working outward from the
subexpressions.  The subexpression(s) \code{y - mu} are of type
\code{vector} because the variables \code{y} and \code{mu} are of type
\code{vector}.  The transpose of this expression, the subexpression
\code{(y - mu)'} is of type \code{row\_vector}.  Multiplication is
left associative and transpose has higher precedence than
multiplication, so the above expression is equivalent to the following
well-formed, fully specified form.
%
\begin{quote}
\code{((y - mu) * Sigma) * ((y - mu)')}
\end{quote}
%
The type of subexpression \code{(y - mu) * Sigma} is inferred to be
\code{vector}, being the result of multiplying a (column) vector by a
matrix.  The whole expression's type is thus the type of a vector
multiplied by a column vector, which produces a \code{real} value.



\subsection{Operator Precedence and Associativity}

The arithmetic operators have the following precedence and
associativity.
%
\begin{center}
\begin{tabular}{c|ccl|l}
{\it Operator} & {\it Precedence} & {\it Associativity} & {\it
  Placement} & {\it Description}
\\ \hline \hline
\code{+} & 0 & left & binary infix & addition
\\
\code{-} & 0 & left & binary infix & subtraction
\\ \hline
\code{*} & 1 & left & binary infix & multiplication
\\
\code{/} & 1 & left & binary infix & division
\\ \hline
\code{-} & 2 & n/a & unary prefix & negation
\\ \hline
\code{'} & 3 & n/a & unary posfix & transposition
\end{tabular}
\end{center}
%
Other expression-forming operations, such as function application and
subscripting bind more tightly than any of the arithmetic.  

The precedence and associativity determine how expressions are
interpreted.  Because addition is left associative, the expression
\code{a+b+c} is interpreted as \code{(a+b)+c}.  Similarly,
\code{a/b*c} is interpreted as \code{(a/b)*c}.  

Because multiplication has higher precedence than addition, the
expression \code{a*b+c} is interpreted as \code{(a*b)+c} and the
expression \code{a+b*c} is interpreted as \code{a+(b*c)}.  Similarly,
\code{2*x+3*-y} is interpreted as \code{(2*x)+(3*(-y))}.

Transposition binds tighter than all other operations, so that
\code{u*v'} is interpeted as \code{u*(v')} and \code{u'*v} as
\code{(u')*v}.

\section{Subscripting}

\Stan arrays, matrices, vectors, and row vectors are all accessed
using the same array-like notation.  For instance, if \code{x} is a
variable of type \code{real[]} (a one-dimensional array of reals)
then \code{x[1]} is the value of the first element of the
array.  

Subscripting has higher precedence than any of the arithmetic
operations.  For example, \code{alpha*x[1]} is equivalent to
\code{alpha*(x[1])}.  

Multiple subscripts may be provided within a single pair of square
brackets.  If \code{x} is of type \code{real[,]}, a two-dimensional
array, then \code{x[2,501]} is of type \code{real}.

\subsection{Accessing Subarrays}

The subscripting operator also returns subarrays of arrays.  For
example, if \code{x} is of type \code{real[,,]}, then \code{x[2]}
is of type \code{real[,]}, and \code{x[2,3]} is of type
\code{real[]}.  As a result, the expressions \code{x[2,3]} and
\code{x[2][3]} have the same meaning.  

\subsection{Accessing Matrix Rows}

If \code{Sigma} is a variable of type \code{matrix}, then
\code{Sigma[1]} denotes the first row of \code{Sigma} and has the
type \code{row\_vector}.  

\subsection{Mixing Array and Vector/Matrix Indexes}

\Stan supports mixed indexing of arrays and their vector, row vector
or matrix values.  For example, if \code{m} is of type
\code{matrix[,]}, a two-dimensional array of matrices, then
\code{m[1]} refers to the first row of the array, which is a
one-dimensional array of matrices.  More than one index may be used,
so that \code{m[1,2]} is of type \code{matrix} and denotes the matrix
in the first rwo and second column of the array.  Continuing to add
indices, \code{m[1,2,3]} is of type \code{row\_vector} and denotes
the third row of the matrix denoted by \code{m[1,2]}.  Finally,
\code{m[1,2,3,4]} is of type \code{real} and denotes the value in the
third row and fourth column of the matrix that is found at the first
row and second column of the array \code{m}.

\section{Function Application}

\Stan provides a broad-range of built in mathematical and statistical
functions, which are documented in \refpart{built-in-functions}.

Expressions in \Stan may consist of the name of function followed by a
sequence of zero or more argument expressions.  For instance,
\code{log(2.0)} is the expression of type \code{real} denoting the
result of applying the natural logarithm to the value of the real
literal \code{2.0}.

Syntactically, function application has higher precedence than any of
the other operators, so that \code{y + log(x)} is interpreted as
\code{y + (log(x))}.

\subsection{Type Signatures and Result Type Inference}

Each function has a type signature which determines the allowable type
of its arguments and its return type.  For instance, the function
signature for the logarithm function can be expressed as
%
\begin{quote}
\code{real log(real);}
\end{quote}
%
and the signature for the \code{multiply\_log} function is
%
\begin{quote}
\code{real multiply\_log(real,real);}
\end{quote}
%
A function is uniquely determined by its name and its sequence of
argument types.  For instance, the following two functions are
different functions.
%
\begin{quote}
\code{real mean(real[]);}
\\
\code{real mean(vector);}
\end{quote}
%
The first applies to a one-dimensional array of real values and the
second to a vector.

The identity conditions for functions explicitly forbids having two
functions with the same name and argument types but different return
types.  This restriction also makes it possible to infer the type of a
function expression compositionally by only examining the type of its
subexpressions. 

\subsection{Constants}

Constants in \Stan are nothing more than nullary (no-argument)
functions.  For instance, the mathematical constants $\pi$ and $e$ are
represented as nullary functions named \code{pi()} and \code{e()}.

\subsection{Type Promotion and Function Resolution}

Because of integer to real type promotion, rules must be established
for which function is called given a sequence of argument types.  The
scheme employed by \Stan is the same as that used by \Cpp, which
resolves a function call to the function requiring the minimum number
of type promotions.  

For example, consider a situation in which the following two function
signatures have been registered for \code{foo}.
%
\begin{quote}
\code{real foo(real,real);}
\\
\code{int foo(int,int);}
\end{quote}
%
The use of \code{foo} in the expression \code{foo(1.0,1.0)} resolves
to \code{foo(real,real)}, and thus the expression \code{foo(1.0,1.0)}
itself is assigned a type of \code{real}.  

Because integers may be promoted to real values, the expression
\code{foo(1,1)} could potentially match either \code{foo(real,real)}
or \code{foo(int,int)}.  The former requires two type promotions and
the latter requires none, so \code{foo(1,1)} is resolved to function
\code{foo(int,int)} and is thus assigned the type \code{int}.

The expression \code{foo(1,1.0)} has argument types \code{(int,real)}
and thus does not explicitly match either function signature.  By
promoting the integer expression \code{1} to type \code{real}, it is
able to match \code{foo(real,real)}, and hence the type of the
function expression \code{foo(1,1.0)} is \code{real}.

In some cases (though not for any built-in \Stan functions), a
situation may resolve in which the function referred to by an
expression remains ambiguous.  For example, consider a situation in
which there are exactly two functions named \code{bar} with the
following signatures.
%
\begin{quote}
\code{real bar(real,int);}
\\
\code{real bar(int,real);}
\end{quote}
%
With these signatures, the expression \code{bar(1.0,1)} and
\code{bar(1,1.0)} resolve to the first and second of the above
functions, respectively.  The expression \code{bar(1.0,1.0)} is
illegal because real values may not be demoted to integers.  

The expression \code{bar(1,1)} is illegal for a different reason.
Both of the function signatures above have consistent argument types.
If the first argument is promoted to a real value, it matches the
first signature, whereas if the second argument is promoted to a real
value, it matches the second signature.  The problem is that these
both require one promotion, so the function name \code{bar} is
ambiguous.  In these situations where there is no function requiring
fewer promotions than all others, the \Stan compiler will flag the
epression \code{bar(1,1)} as illegal and list the potentially matching
ambiguous functions.


\subsection{Extending \Stan with User-Defined Functions}

\Stan enables users to add their own functions by defining appropirate
\Cpp functions and registering their signatures with the \Stan
compiler.  Details are provided in \refappendix{user-defined-functions}.


\section{Parentheses for Grouping}

Any expression wrapped in parentheses is also an expression. Like in
\Cpp, but unlike in \R, only the round parentheses, \code{(} and
\code{)}, are allowed.  The square bracketes \code{[} and \code{]} are
reserve for array indexing and the curly braces \code{\{} and
\code{\}} for grouping statements.

With parentheses it is possible to explicitly group subexpressions
with operators.  Without parentheses, the expression \code{1 + 2 * 3}
has a subexpression \code{2 * 3} and evaluates to 7.  With
parentheses, this grouping may be made explicit with the expression
\code{1 + (2 * 3)}.  More importantly, the alternative evaluate order
becomes possible with \code{(1 + 2) * 3}, which evaluates to 6.



\chapter{Statements}

The blocks of a \Stan program (see \refchapter{blocks}) are made up of
variable declarations and statements.  Unlike programs in \BUGS or
\JAGS, the declarations and statments making up a \Stan program are
executed in the order in which they are written.  Thus variables need
to be defined before they are used, or there will be undefiend
behavior.  Like \BUGS and \JAGS, \Stan has two kinds of atomic
statements, assignment statements and probability statements.  Also
like those other languages, statements may be grouped into sequences
and into for loops.  In addition, \Stan allows local variables to be
declared in blocks and also allows an empty statement consisting only
of a semicolon.

\section{Assignment Statement}

An assignment statement consists of a variable (possibly multivariate
with indexing information) and an expressions.  Executing an
assignment statement evaluates the expression on the right-hand side
and assigns it to the (indexed) variable on the left-hand side.  An
example of a simple assignment is
%
\begin{quote}
\code{n <- 0;}
\end{quote}
%
Executing this statement assigns the value of the expression \code{0},
which is the integer zero, the variable \code{n}.  For an assignment
to be well-formed, the type of the expression on the right-hand side
should be compatible with the type of the (indexed) variable on the
left-hand side.  For the above example, because \code{0} is an
expression of type \code{int}, the variable \code{n} must be declared
as being of type \code{int} or of type \code{real}.  If the variable
is of type \code{real}, the integer zero is promoted to a
floating-point zero and assigned to the variable.  After the
assignment statement executes, the variable \code{n} will have the
value zero (either as an integer or a continuous value, depending on
its type).

Syntactically, every assignment statement must be followed by a
semicolon.  Otherwise, whitespace between the tokens does not matter
(the tokens here being the left-hand-side (indexed) variable, the
assignment operator, the right-hand-side expression and the
semicolon).

Because the right-hand side is evaluated first, it is possible to
increment a variable in \Stan just as in \Cpp and other programming
languages by writing
%
\begin{quote}
\code{n <- n + 1;}
\end{quote}

The left-hand side may contain indices for array, matrix, or vector
data structures.  For instance, if \code{Sigma} is of type
\code{matrix}, then 
%
\begin{quote}
\code{Sigma[1,1] <- 1.0;}
\end{quote}
%
sets the value of the first row and first column of \code{Sigma} to one.

Assignments can involve complex objects of any type.  If \code{Sigma}
and \code{Omega} are matrices and \code{sigma} is a vector, then the
following assignment statement, in which the expression and variable
are both of type \code{matrix}, is well formed.
%
\begin{quote}
\begin{Verbatim}
Sigma
  <- diag_matrix(sigma) 
     * Omega 
     * diag_matrix(sigma);
\end{Verbatim}
\end{quote}
%
This example also illustrates the preferred form of splitting a
complex assignment statement and its expression across lines.

Assignments to slices of larger multi-variate data structures is
supported by \Stan.  For example, \code{a} is an array of type
\code{real[,]} and \code{b} is an array of type \code{real[]}, then
the following two statements are both well-formed.
%
\begin{quote}
\begin{Verbatim}
a[3] <- b;
b <- a[4];
\end{Verbatim}
\end{quote}
%
Similarly, if \code{x} is variable declared to have type
\code{row\_vector} and \code{Y} is a variable declared as type
\code{matrix}, then the following sequence of statements to swap the
first two rows of \code{Y} is well formed.
%
\begin{quote}
\begin{Verbatim}
x <- Y[1];
Y[1] <- Y[2];
Y[2] <- x;
\end{Verbatim}
\end{quote}

\section{Sampling Statements}

Like \BUGS and \JAGS, \Stan supports probability statements in
sampling notation, such as
%
\begin{quote}
\begin{Verbatim}
y ~ normal(mu,sigma);
\end{Verbatim}
\end{quote}
%
The name ``sampling statement'' is meant to be suggestive, not
interpreted literally.  Conceptually, the variable \code{y}, which may
be an unobserved parameter or modeled observed data, is being declared
to have the distribution indicated by the right-hand side of the
sampling statement.

Executing such a statement does not perform any sampling.  In \Stan, a
sampling statement is merely a notational convenenience.  The above
sampling statement could be written as an assignment statement using
the reserved variable \code{lp\_\_} as
%
\begin{quote}
\begin{Verbatim}
lp__ <- lp__ + normal_log(y,mu,sigma);
\end{Verbatim}
\end{quote}
%
The variable \code{lp\_\_} acts as an accumulator for the log
(proportional) probability defined by the model as a function of the
parameters and data.

In general, a sampling statement of the form
%
\begin{quote}
\begin{Verbatim}
ex0 ~ dist(ex1,...,exN);
\end{Verbatim}
\end{quote}
%
involving subexpressions \code{ex0} through \code{exN} (including the
case where \code{N} is zero) will be well formed if and only if the
corresponding assignment statement is well-formed,
%
\begin{quote}
\begin{Verbatim}
lp__ <- lp__ + dist_log(ex0,ex1,...,exN);
\end{Verbatim}
\end{quote}
%
This will be well formed if and only if
\code{dist\_log(ex0,ex1,...,exN)} is a well-formed function expression
of type \code{real}.

\subsection{User-Transformed Variables}

The left-hand side of a sampling statement may be a complex
expression.  For instance, it is legal syntactically to write
%
\begin{quote}
\begin{Verbatim}
data {
    double(0,) y;
}
model {
    ....
    log(y) ~ normal(mu,sigma);
    ...
}
\end{Verbatim}
\end{quote}
%
Unfortunately, this is not enough to properly model \code{y} as having
a lognormal distribution.  The differential change in scale resulting
for the transformation, in general given by the log absolute Jacobian
determinant, must be accounted for (see
\refsection{change-of-variables} for full definitions).  For the case
above, the following adjustment will account for the above log
transform.%
%
\footnote{Because $\log | d/dy \log y | = \log | 1/y | = - \log
  |y|$;  see \refsection{change-of-variables}.}
%
\begin{quote}
\begin{Verbatim}
lp__ <- lp__ - log(fabs(y));
\end{Verbatim}
\end{quote}
%

\subsection{Truncated Distributions}

A density function $p(x)$ may be truncated to an interval $(a,b)$ to
define a new density $p_{(a,b)}(x)$ by setting
%
\[ 
p_{\!(a,b)\!}(x) = \frac{p(x)}
                  {\int_a^b p(x') \, dx'}.
\] 
As in \BUGS and \JAGS, \Stan allows probability functions to be
truncated.  For example, a truncated unit normal distribution
restricted to $(-0.5,2.1)$ is encoded as follows.
%
\begin{quote}
\begin{Verbatim} 
y ~ normal(0,1) T(-0.5,2.1);
\end{Verbatim}
\end{quote}
% 
Truncated distributions are translated as an addition summation for
the accumulated log probability.  For instance, this example has the
same translation as
%
\begin{quote}
\begin{Verbatim}
lp__ <- lp__ - log(normal_p(2.1,0,1) - normal_p(-0.5,0,1));
\end{Verbatim}
\end{quote}
%
The function \code{normal\_p} represents the cumulative normal
distribution function.  For example, \code{normal\_p(2.1,0,1)} evaluates to 
\[
\int_{-\infty}^{2.1} \mbox{\sf Norm}(x|0,1) \, dx,
\]
%
which is the probability a unit normal variable takes on values less
than 2.1, or about 0.95.

As with constrained variable declarations, truncation can be one
sided.  The density $p(x)$ can be truncated below by $a$ to define a
density $p_{(a,)}(x)$ with support $(a,\infty)$ by setting
%
\[
p_{(a,)}(x) = \frac{p(x)}
                 {\int_a^{\infty} p(x') \, dx'}.
\]
For example, the unit normal distribution truncated below at 0.5 would
be represented as
%
\begin{quote}
\begin{Verbatim} 
y ~ normal(0,1) T(-0.5,);
\end{Verbatim}
\end{quote}
% 
The truncation has the same effect as the following direct update to
the accumulated log probability.
%
\begin{quote}
\begin{Verbatim}
lp__ <- lp__ - log(1 - normal_p(-0.5,0,1));
\end{Verbatim}
\end{quote}

The density $p(x)$ can be truncated above by $b$ to define a density
$p_{(,b)}(x)$ with support $(-\infty,a)$ by setting
\[
p_{(,b)}(x) = \frac{p(x)}
                    {\int_{-\infty}^b p(x') \, dx'}.
\]
For example, the unit normal distribution truncated above at 2.1 would
be represented as
%
\begin{quote}
\begin{Verbatim} 
y ~ normal(0,1) T(,2.1);
\end{Verbatim}
\end{quote}
% 
The truncation has the same effect as the following direct update to
the accumulated log probability.
%
\begin{quote}
\begin{Verbatim}
lp__ <- lp__ - log(normal_p(2.1,0,1));
\end{Verbatim}
\end{quote}

In all cases, the truncation is only well formed if there is an
appropriate cumulative distribution function defined.
\refchapter{discrete-prob-functions} and
\refchapter{continuous-prob-functions} document the available discrete
and continuous cumulative distribution functions.

For continuous distributions, truncation points must be expressions of
type \code{int} or \code{real}.  For discrete distributions, truncation
points must be expressions of type \code{int}.


\subsection{Scope of\, \code{lp\_\_}}

The variable \code{lp\_\_} is only defined in the \code{parameter},
\code{transformed parameter}, and \code{model} blocks (see
\refchapter{blocks}).  The variable \code{lp\_\_} is undefined (and
may not be declared by the user) in the \code{data}, \code{transformed
  data} and \code{generated quantity} blocks.

\subsection{User-Defined Distributions}

Users may add their own probability functions and cumulative
distribution by adding functions of the appropriate type.  If the
appropriate cumulative distribution is available to match a
probability function, truncated versions of that probabilty function
may be used. 

See \refappendix{user-defined-functions} for details on how to add
user-defined functions to \Stan.


\section{For Loops}

Like \BUGS, \JAGS and \R, \Stan supports bounded for loops.  Suppose
\code{N} is a variable of type \code{int}, \code{y} is a
one-dimensional array of type \code{real[]}, and \code{mu} and
\code{sigma} are variables of type \code{real}.  Furthermore, suppose
that \code{n} has not been defined as a variable. Then the following
is a well-formed for-loop statement.
%
\begin{quote}
\begin{Verbatim}
for (n in 1:N) {
   y[n] ~ normal(mu,sigma);
}
\end{Verbatim}
\end{quote}
%
The loop variable is \code{n}, the loop bounds are the values in the
range \code{1:N}, and the body is the statement following the
loop bounds.  

\subsection{Loop Variable Typing and Scope}

The bounds in a for loop must be integers.  Unlike in \R, the loop is
always interpreted as an upward counting loop.  The range \code{L:H}
will cause the loop to execute the loop with the loop variable taking
on all integer values greater than or equal to \code{L} and less than
or equal to \code{H}.  For example, the loop \code{for (n in 2:5)}
will cause the body of the for loop to be executed with \code{n} equal
to 2, 3, 4, and 5, in order.  The variable and bound \code{for (n in
  5:2)} will not execute anything because there are no integers
greater than or equal to 5 and less than or equal to 2.

\subsection{Brackets in For Loops}

The body of a for loop can be any statement.  Stan thus allows the
brackets in a single-statement for loop to be dropped. Whitespace is
optional, as usual, so that the following example is the same as the
one above.
%
\begin{quote}
\begin{Verbatim}
for (n in 1:N) 
 y[n] ~ normal(mu,sigma);
\end{Verbatim}
\end{quote}
%
For loops bind more tightly than statement sequencing, so that the
misleadingly indented program fragment
%
\begin{quote}
\begin{Verbatim}
for (n in 1:N) 
  y[n] ~ normal(mu,sigma);
  z[n] ~ normal(mu,sigma);
\end{Verbatim}
\end{quote}
%
behaves the same way as the properly indented and bracketed version
%
\begin{quote}
\begin{Verbatim}
for (n in 1:N) {
  y[n] ~ normal(mu,sigma);
}
z[n] ~ normal(mu,sigma);
\end{Verbatim}
\end{quote}
%
Neither of these programs will compile because the variable \code{n}
indexing \code{z} in \code{z[n]} is defined in the for loop and hence
out of scope outside the for loop.





\chapter{Blocks}\label{blocks.chapter}

A \Stan program is organized into a sequence of named blocks, the
bodies of which consist of variable declarations followed by
statements.  The full set of blocks is exemplified in the following
skeletal \Stan program.
%
\begin{quote}
\begin{Verbatim} 
data { 
  ... declarations ...
}
transformed data { 
   ... declarations ... statements ... 
}
parameters { 
   ... declarations ... 
}
transformed parameters { 
   ... declarations ...
   ... statements ...
}
model { 
   ... statements ...
}
derived quantities {
   ... declarations ...
   ... statements ...
}
\end{Verbatim}
\end{quote}
%
All of the blocks other than the \code{model} block are optional.  Any
blocks that appear must be in the order above.


\part{Built-In Functions}\label{built-in-functions.part}

\chapter{Built-in Functions}

\Stan supports a wide range of built-in functions.  These functions
operate over and return values spanning the complete range of data
types.  

The following chapters in this part describe basic functions returning
integers and returning real values, array and matrix functions, and
probability functions and cumulative distributions.

\section{Function Signatures}

The documentation of the special functions begins with a function
signature.  This determines the type of arguments taken by the
function and the type of value returned.  

\subsection{Overloading}

\Stan relies on function overloading, which means there can be several
different functions with the same name.  Functions are determined
uniquely by the combination of their name and the type of their
arguments.

For example, \Stan includes two built-in functions named \code{max}, one that
operates on integers to return an integer, with signature
%
\begin{quote}
\begin{Verbatim}
int max(int m, int n)
\end{Verbatim}
\end{quote}
%
and one that operates over reals, with signature
%
\begin{quote}
\begin{Verbatim}
real max(real x, real y)
\end{Verbatim}
\end{quote}
%
The appropriate instance is called based on the arguments provided.

The two functions named \code{max} are distinguished by their argument
types.  It would not be legal to add a third function with signature
\code{real max(int,int)}, as it would lead to a conflict with the
existing function of name \code{max} and argument types
\code{(int,int)}, even though it has a different return type.


\section{Integer-to-Real Type Promotion}

Integer values may be passed to functions requiring real values.  This
is not unrelated to the fact that integer values may be assigned to
real variables.  In both cases, the underlying \Cpp code handles the
promotion of the underlying integer type to the underlying
floating-point type.

Consider again the two functions \code{max(int,int)} and
\code{max(real,real}), and suppose these are the only two functions
named \code{max} (they are the only two of that name built into
\Stan).  If \code{m} is an integer variable and \code{x} a real
variable, the call \code{max(m,x)} must be resolved as referring to
\code{max(double,double)}, because integers can be promoted to real
values, but not vice-versa.  

If \code{n} is another integer variable, a call to \code{max(m,n)}
could conceivably call either function named \code{max}.  The function
\code{max(int,int)} requires no promotions, whereas
\code{max(double,double)} requires two, so the first is invoked.  The
general rule is that the function call matches the function requiring
the fewest promotions.

Even this simple disambiguation scheme leads to possible ambiguity
(though \Stan's built-in functions avoid it).  If there were two functions,
\code{foo(int,real)} and \code{foo(real,int)} and if \code{m} and
\code{n} were integer variales, a call to \code{foo(m,n)} would be
ambiguous.  Either function could be matched with one promotion and
there is no better-matching function.  In such cases, the call will
not compile.  This could be resolved by assigning one variable to a
temporary, as in the following example.
%
\begin{quote}
\begin{Verbatim}
int m;  int n;  real x;  real y;  
x <- m;  y <- n;
# foo(m,n);  // illegal!
foo(x,n);    // calls foo(double,int)
foo(m,y);    // calls foo(int,double)
\end{Verbatim}
\end{quote}





\chapter{Integer-Valued Basic Functions}

This chapter describes \Stan's built-in function that operate on real
and integer arguments and return results of type integer.


\section{Integer-Valued Arithmetic Operators}

\Stan's arithmetic is based on standard double-precision \Cpp integer and
floating-point arithmetic.  If the arguments to an arithmetic operator
are both integers, as in \code{2+2}, integer arithmetic is used.  If
one argument is an integer and the other a floating-point value, as in
\code{2.0+2}, \code{2+2.0}, then the integer is promoted to a floating
point value and floating-point arithmetic is used.

Integer arithmetic behaves slightly differently than floating point
arithmetic.  The first difference is how overflow is treated.  If the
sum or product of two integers overflows the maximum integer
representable, the result is an undesirable wraparound behavior at the
bit level.  If the integers were first promoted to real numbers, they
would not overlflow a floating-point representation.  There are no
extra checks in \Stan to flag overflows, so it is up to the user to
make sure it does not occur.

Secondly, because the set of integers is not closed under division and
there is no special infinite value for integers, integer division
behaves differently.  For integer division by values other than zero,
the result is rounded toward 0.  For instance, positive results are
rounded down, as in \code{1/2 = 0} and \code{5/3 = 1}, whereas
negative results are rounded up, as in \code{(-1)/2 = 0} and
\code{(-5)/33 = -1}.

Unlike floating point division, where \code{1.0/0.0} produces the
special positive infinite value, integer division by zero, as in
\code{1/0}, has undefined behavior in the \Cpp standard.  For example,
the \clang compiler on Mac OS X returns 3764, whereas the \gpp
compiler throws a floating-point exception and aborts the program with
a warning.  As with overflow, it is up to the user to make sure
integer divide-by-zero does not occur.

\subsection{Binary Infix Operators}

\begin{description}
%
\fitem{real}{operator+}{real \farg{x}, real \farg{y}}{
The sum of the addends \farg{x} and \farg{y}}
%
\fitem{real}{operator-}{real \farg{x}, real \farg{y}}{
The difference between the minuend \farg{x} and subtrahend \farg{y}}
%
\fitem{real}{operator*}{real \farg{x}, real \farg{y}}{
The product of the factors \farg{x} and \farg{y}}
%
\fitem{real}{operator/}{real \farg{x}, real \farg{y}}{
The integer quotiont of the dividend \farg{x} and divisor \farg{y}}
%
\end{description}

\subsection{Unary Prefix Operators}

\begin{description}
\fitem{real}{operator-}{real \farg{x}}{
The negation of the the subtrahend \farg{x}}

\fitem{real}{operator+}{real \farg{x}}{
The promotion of addend \farg{x} to a real, which is a no-op
for real inputs}
\end{description}

\section{Absolute Function}

\begin{description}
%
\fitem{int}{abs}{int \farg{x}}{
The absolute value of \farg{x}}
%
\end{description}
%

\section{Bound Functions}
%
\begin{description}
\fitem{int}{min}{int \farg{x}, int \farg{y}}{
The minimum of \farg{x} and \farg{y}}
%
\fitem{int}{max}{int \farg{x}, int \farg{y}}{
The maximum of \farg{x} and \farg{y}}
%
\end{description}


\chapter{Real-Valued Basic Functions}

This chapter describes built-in functions that take zero or more real
or integer arguments and return real values.  Constants are
represented as functions with no arguments and must be called as such.

\section{Mathematical Constants}

%
\begin{description}
%
\fitem{real}{pi}{}{
  $\pi$, the ratio of a circle's circumference to its diameter}
%
\fitem{real}{e}{}{
 $e$, the base of the natural logarithm}
%
\fitem{real}{sqrt2}{}{
The square root of 2}
%
\fitem{real}{log2}{}{
The natural logarithm of 2}
%
\fitem{real}{log10}{}{
The natural logarithm of 10}
%
\end{description}

\section{Special Values}

\begin{description}
\fitem{real}{nan}{}{
Not-a-number, a special non-finite real value returned to signal an error}
%
\fitem{real}{infinity}{}{
 Positive infinity, a special non-finite real value larger than all
  finite numbers}
%
\fitem{real}{negative\_infinity}{}{ 
 Negative infinity, a special non-finite real value smaller than all
  finite numbers}
%
\fitem{real}{epsilon}{}{
The smallest positive real value representable}
%
\fitem{real}{negative\_epsilon}{}{
The largest negative real value representable}
%
\end{description}

\section{Logical Functions}

\begin{description}
%
\fitem{real}{if\_else}{int cond, real \farg{x}, real \farg{y}}{
\farg{x} if \farg{cond} is non-zero, and \farg{y} otherwise}
%
\fitem{real}{step}{real \farg{x}}{
0 if \farg{x} is negative and 1 otherwise}
%
\end{description}


\section{Real-Valued Arithmetic Operators}\label{real-valued-arithmetic-operators.section}

The arithmetic operators are presented using \Cpp notation.  For
instance \code{operator+(x,y)} refers to the binary addition operator
and \code{operator-(x)} to the unary negation operator.  In \Stan
programs, these are written using the usual infix and prefix notations
as \code{x~+~y} and \code{-x}, respectively.

\subsection{Binary Infix Operators}

\begin{description}
%
\fitem{real}{operator+}{real \farg{x}, real \farg{y}}{
The sum of the addends \farg{x} and \farg{y}}
%
\fitem{real}{operator-}{real \farg{x}, real \farg{y}}{
The difference between the minuend \farg{x} and subtrahend \farg{y}}
%
\fitem{real}{operator*}{real \farg{x}, real \farg{y}}{
The product of the factors \farg{x} and \farg{y}}
%
\fitem{real}{operator/}{real \farg{x}, real \farg{y}}{
The quotiont of the dividend \farg{x} and divisor \farg{y}}
%
\end{description}

\subsection{Unary Prefix Operators}

\begin{description}
\fitem{real}{operator-}{real \farg{x}}{
The negation of the the subtrahend \farg{x}}

\fitem{real}{operator+}{real \farg{x}}{
The promotion of addend \farg{x} to a real, which is a no-op
for real inputs}
\end{description}


\section{Absolute Functions}

\begin{description}
%
\fitem{real}{abs}{real \farg{x}}{
The absolute value of \farg{x}}
%
\fitem{real}{fabs}{real \farg{x}}{
The absolute value of \farg{x}}
%
\fitem{real}{fdim}{real \farg{x}, 
                 real \farg{y}}{
The positive difference between \farg{x} and \farg{y}, which is
\farg{x} - \farg{y} if \farg{x} is greater than \farg{y} and 0 otherwise}
%
\end{description}

\section{Bounds Functions}

\begin{description}
%
\fitem{real}{fmin}{real \farg{x}, real \farg{y}}{
The minimum of \farg{x} and \farg{y}}
%
\fitem{real}{fmax}{real \farg{x}, real \farg{y}}{
The maximum of \farg{x} and \farg{y}}
%
\end{description}

\section{Arithmetic Functions}
%
\begin{description}
\fitem{real}{fmod}{real \farg{x}, real \farg{y}}{
The real value remainder after dividing \farg{x} by \farg{y}}
%
\end{description}

\section{Rounding Functions}

\begin{description}
%
\fitem{real}{floor}{real \farg{x}}{
The floor of \farg{x}, which is the largest integer less
than or equal to \farg{x}, converted to a real value}
%
\fitem{real}{ceil}{real \farg{x}}{
The ceiling of \farg{x}, which is the smallest integer greater
than or equal to \farg{x}, converted to a real value}
%
\fitem{real}{round}{real \farg{x}}{
The nearest integer to \farg{x}, converted to a real value}
%
\fitem{real}{trunc}{real \farg{x}}{
The integer nearest to but no larger in magnitude than \farg{x},
converted to a double value}
%
\end{description}

\section{Power and Logarithm Functions}

\begin{description}
%
\fitem{real}{sqrt}{real \farg{x}}{
The square root of \farg{x}}
%
\fitem{real}{cbrt}{real \farg{x}}{
The cube root of \farg{x}}
%
\fitem{real}{square}{real \farg{x}}{
The square of \farg{x}}
%
\fitem{real}{exp}{real \farg{x}}{
The natural exponential of \farg{x}}
%
\fitem{real}{exp2}{real \farg{x}}{
The base-2 exponential of \farg{x}}
%
\fitem{real}{expm1}{real \farg{x}}{
The natural exponential of \farg{x} minus 1}
%
\fitem{real}{log}{real \farg{x}}{
The natural logarithm of \farg{x}}
%
\fitem{real}{log2}{real \farg{x}}{
The base-2 logarithm of \farg{x}}
%
\fitem{real}{log10}{real \farg{x}}{
The base-10 logarithm of \farg{x}}
%
\fitem{real}{pow}{real \farg{x}, real \farg{y}}{
\farg{x} raised to the power of \farg{y}}
%
\end{description}




\section{Link Functions}

\begin{description}
%
\fitem{real}{logit}{real \farg{x}}{
The log odds, or logit, function applied to \farg{x}}
%
\fitem{real}{inv\_logit}{real \farg{x}}{
The logistic sigmoid function applied to \farg{x}}
%
\fitem{real}{inv\_cloglog}{real \farg{x}}{
The inverse of the complement log-log function applied to \farg{x}}
%
\end{description}


\section{Trigonometric Functions}

\begin{description}
%
\fitem{real}{hypot}{real \farg{x}, real \farg{y}}{
The length of the hypoteneuse of a right triangle with sides of
length \farg{x} and \farg{y}}
%
\fitem{real}{cos}{real \farg{x}}{
The cosine of the angle \farg{x} (in radians)}
%
\fitem{real}{sin}{real \farg{x}}{
The sine of the angle \farg{x} (in radians)}
%
\fitem{real}{tan}{real \farg{x}}{
The tangent of the angle \farg{x} (in radians)}
%
\fitem{real}{acos}{real \farg{x}}{
The princpipal arc (inverse) cosine (in radians) of \farg{x}}
%
\fitem{real}{asin}{real \farg{x}}{
The principal arc (inverse) sine (in radians) of \farg{x}}
%
\fitem{real}{atan}{real \farg{x}}{
The principal arc (inverse) tangent (in radians) of \farg{x}}
%
\fitem{real}{atan2}{real \farg{x}, real \farg{y}}{
The principal arc (inverse) tangent (in radians) of \farg{x} divided
by \farg{y}}
%
\end{description}

\section{Hyperbolic Trigonometric Functions}

\begin{description}
%
\fitem{real}{cosh}{real \farg{x}}{
The hyperbolic cosine of \farg{x} (in radians)}
%
\fitem{real}{sinh}{real \farg{x}}{
The hyperbolic sine of \farg{x} (in radians)}
%
\fitem{real}{tanh}{real \farg{x}}{
The hyperbolic tangent of \farg{x} (in radians)}
%
\fitem{real}{acosh}{real \farg{x}}{
The inverse hyperbolic cosine (in radians) of \farg{x}}
%
\fitem{real}{asinh}{real \farg{x}}{
The inverse hyperbolic sine (in radians) of \farg{x}}
%
\fitem{real}{atanh}{real \farg{x}}{
The inverse hyperbolic tangent (in radians) of \farg{x}}
%
\end{description}

\section{Probability-Related Functions}

\begin{description}
%
\fitem{real}{erf}{real \farg{x}}{
The error function of \farg{x}}
%
\fitem{real}{erfc}{real \farg{x}}{
The complementary error function of \farg{x}}
%
\fitem{real}{Phi}{real \farg{x}}{
The cumulative normal density function of \farg{x}}
%
\fitem{real}{log\_loss}{int \farg{y}, real \farg{y\_hat}}{
The log loss of predicting probabilty \farg{y\_hat} for 
binary outcome \farg{y}}
%
\end{description}




\section{Combinatorial Functions}

\begin{description}
%
\fitem{real}{tgamma}{real \farg{x}}{
The gamma function applied to \farg{x}}
%
\fitem{real}{lgamma}{real \farg{x}}{
The natural log of the gamma function applied to \farg{x}}
%
\fitem{real}{lmgamma}{int \farg{n}, real \farg{x}}{
The natural logarithm of the multinomial gamma function with \farg{n}
dimensions applied to \farg{x}}
%
\fitem{real}{lbeta}{real \farg{x}, real \farg{y}}{
The natural log of the beta function applied to \farg{x}}
%
\fitem{real}{binomial\_coefficient\_log}{real \farg{x}, real \farg{y}}{
The natural logarithm of the binomial coefficient of \farg{x} choose
\farg{y}, generalized to real values via the gamma function}
%
\end{description}


\section{Composed Functions}

\begin{description}
%
\fitem{real}{fma}{real \farg{x}, 
               real \farg{y},
               real \farg{z}}{
\farg{z} plus the result of \farg{x} multiplied by \farg{y}}
%
\fitem{real}{multiply\_log}{real \farg{x}, real \farg{y}}{ 
The product of \farg{x} and the natural logarithm of \farg{y}}
%
\fitem{real}{log1p}{real \farg{x}}{
The natural logarithm of 1 plus \farg{x}}
%
\fitem{real}{log1m}{real \farg{x}}{
The natural logarithm of 1 minus \farg{x}}
%
\fitem{real}{log1p\_exp}{real \farg{x}}{ 
The natural logarithm of one plus the natural exponentiation of
\farg{x}}
%
\fitem{real}{log\_sum\_exp}{real \farg{x}, real \farg{y}}{ 
The natural logarithm of the sum of the natural exponentiation
of \farg{x} and the natural exponentiation of \farg{y}}
%
\end{description}




\chapter{Array Operations}


\begin{description}
\fitem{real}{sum}{real \farg{x}[]}
The sum of the elements in \farg{x}
%
\fitem{real}{mean}{real \farg{x}[]}
The sample mean of the elements in \farg{x}
%
\fitem{real}{variance}{real \farg{x}[]}
The sample variance of the elements in \farg{x} (based on
dividing by \code{length - 1})
%
\fitem{real}{sd}{real \farg{x}[]} The sample standard deviation of
elements in \farg{x} (divide by \code{length - 1})
%
\fitem{real}{log\_sum\_exp}{real \farg{x}[]}
The log of the sum of the exponentials of the elements in \farg{x}
\end{description}

\chapter{Matrix Operations}\label{matrix-operations.chapter}

\section{Matrix Arithmetic Operators}

\Stan supports the basic matrix operations using infix, prefix and
postfix operations.  This section lists the operations supported by
\Stan along with their argument and result types.

\subsection{Infix Matrix Operators}

\begin{description}
%
\fitem{vector}{operator+}{vector \farg{x}, vector \farg{y}}{The sum of
the vectors \farg{x} and \farg{y}}
%
\fitem{row\_vector}{operator+}{row\_vector \farg{x}, row\_vector \farg{y}}{The sum of
the row vectors \farg{x} and \farg{y}}
%
\fitem{matrix}{operator+}{matrix \farg{x}, matrix \farg{y}}{The sum of
the matrices \farg{x} and \farg{y}}
%
\end{description}
\vspace*{-4pt}
\begin{description}
\fitem{vector}{operator-}{vector \farg{x}, vector \farg{y}}{The difference between
the vectors \farg{x} and \farg{y}}
%
\fitem{row\_vector}{operator-}{row\_vector \farg{x}, row\_vector \farg{y}}{The
  difference between the the row vectors \farg{x} and \farg{y}}
%
\fitem{matrix}{operator-}{matrix \farg{x}, matrix \farg{y}}{The difference between
  the matrices \farg{x} and \farg{y}}
%
\end{description}
\vspace*{-4pt}
\begin{description}
%
\fitem{vector}{operator*}{real \farg{x}, vector \farg{y}}{The product of
the scalar \farg{x} and vector \farg{y}}
%
\fitem{row\_vector}{operator*}{real \farg{x}, row\_vector \farg{y}}{The product of
the scalar \farg{x} and the row vector \farg{y}}
%
\fitem{matrix}{operator*}{real \farg{x}, matrix \farg{y}}{The product of
the scalar \farg{x} and the matrix \farg{y}}
%
%
\fitem{vector}{operator*}{vector \farg{x}, real \farg{y}}{The product of
the scalar \farg{y} and vector \farg{x}}
%
\fitem{matrix}{operator*}{vector \farg{x}, row\_vector \farg{y}}{The product
of the row vector \farg{x} and vector \farg{y}}
%
%
\fitem{row\_vector}{operator*}{row\_vector \farg{x}, real \farg{y}}{The product of
the scalar \farg{y} and row vector \farg{x}}
%
\fitem{real}{operator*}{row\_vector \farg{x}, vector \farg{y}}{The product
of the row vector \farg{x} and vector \farg{y}}
%
\fitem{row\_vector}{operator*}{row\_vector \farg{x}, matrix \farg{y}}{The product
of the row vector \farg{x} and matrix \farg{y}}
%
%
\fitem{matrix}{operator*}{matrix \farg{x}, real \farg{y}}{The product of
the scalar \farg{y} and matrix \farg{x}}
%
\fitem{vector}{operator*}{matrix \farg{x}, vector \farg{y}}{The
  product of the matrix \farg{x} and vector \farg{y}}
%
\fitem{matrix}{operator*}{matrix \farg{x}, matrix \farg{y}}{The product of 
  the matrices \farg{x} and \farg{y}}
%
\end{description}

\subsection{Elementwise Infix Operators}

\begin{description}
%
\fitem{matrix}{operator+}{real \farg{x}, vector \farg{y}}{The result of
adding \farg{x} to every entry in the vector \farg{y}}
%
\fitem{matrix}{operator+}{real \farg{x}, row\_vector \farg{y}}{The result of
adding \farg{x} to every entry in the row vector \farg{y}}
%
\fitem{matrix}{operator+}{real \farg{x}, matrix \farg{y}}{The result of
adding \farg{x} to every entry in the matrix \farg{y}}
%
\fitem{matrix}{operator+}{vector \farg{x}, real \farg{y}}{The result of
adding \farg{y} to every entry in the vector \farg{x}}
%
\fitem{matrix}{operator+}{row\_vector \farg{x}, real \farg{y}}{The result of
adding \farg{y} to every entry in the row vector \farg{x}}
%
\fitem{matrix}{operator+}{matrix \farg{x}, real \farg{y}}{The result of
adding \farg{y} to every entry in the matrix \farg{x}}
%
\end{description}
\vspace*{-4pt}
\begin{description}
%
\fitem{vector}{operator-}{vector \farg{x}, real \farg{y}}{The result of
subtracting \farg{y} from every entry in the vector \farg{x}}
%
\fitem{vector}{operator-}{real \farg{x}, vector \farg{y}}{The result of
adding \farg{x} to every entry in the negation of the vector \farg{y}}
%
\fitem{row\_vector}{operator-}{row\_vector \farg{x}, real \farg{y}}{The result of
subtracting \farg{y} from every entry in the row vector \farg{x}}
%
\fitem{row\_vector}{operator-}{real \farg{x}, row\_vector \farg{y}}{The result of
adding \farg{x} to every entry in the negation of the row vector \farg{y}}
%
\fitem{matrix}{operator-}{matrix \farg{x}, real \farg{y}}{The result of
subtracting \farg{y} from every entry in the matrix \farg{x}}
%
\fitem{matrix}{operator-}{real \farg{x}, matrix \farg{y}}{The result of
adding \farg{x} to every entry in negation of the matrix \farg{y}}
%
\end{description}


\subsection{Prefix Matrix Operators}

\begin{description}
%
\fitem{vector}{operator-}{vector \farg{x}}{The negation of the vector
  \farg{x}}
%
\fitem{row\_vector}{operator-}{row\_vector \farg{x}}{The negation of the row
  vector \farg{x}}
%
\fitem{matrix}{operator-}{matrix \farg{x}}{The negation of the matrix
    \farg{x}}
%
\end{description}


\subsection{Postfix Matrix Operators}

\begin{description}
%
\fitem{matrix}{operator'}{matrix \farg{x}}{The transpose of the matrix
  \farg{x}, written as \code{x'}}
%
\fitem{row\_vector}{operator'}{vector \farg{x}}{The transpose of the vector
  \farg{x}, written as \code{x'}}
%
\fitem{vector}{operator'}{row\_vector \farg{x}}{The transpose of the vector
  \farg{x}, written as \code{x'}}
%
\end{description}


\section{Integer-Valued Matrix Size Functions}

\begin{description}
%
\fitem{int}{rows}{vector \farg{x}}{The number of
rows in the vector \farg{x}}
%
\fitem{int}{rows}{row\_vector \farg{x}}{The number of
rows in the row vector \farg{x}, namely 1}
%
\fitem{int}{rows}{matrix \farg{x}}{The number of
rows in the matrix \farg{x}}
%
\fitem{int}{cols}{vector \farg{x}}{The number of columns
in the vector \farg{x}, namely 1}
%
\fitem{int}{cols}{row\_vector \farg{x}}{The number of columns
in the row vector \farg{x}}
%
\fitem{int}{cols}{matrix \farg{x}}{The number of columns
in the matrix \farg{x}}
\end{description}

\section{Slice and Package Functions}

\begin{description}
%
\fitem{vector}{diagonal}{matrix \farg{x}}{The diagonal
of the matrix as a vector}
%
\end{description}



\section{Linear Algebra Functions and Solvers}



\chapter{Discrete Probabilities}\label{discrete-prob-functions.chapter}

\chapter{Continuous Probabilities}\label{continuous-prob-functions.chapter}


\part{Advanced Topics}


\chapter{Variable Transforms}

To avoid having to deal with constraints while simulating the
Hamiltonian dynamics during sampling, every (multivariate) parameter
in a \Stan model is transformed to an unconstrained variable behind
the scenes by the model compiler.  The transform is based on any
constraints in the parameter's definition.  Constraints that may be
placed on variables include upper and lower bounds, positive ordered
vectors, simplex vectors, correlation matrices and covariance
matrices.  This chapter provides a definition of the transforms used
for each type of variable.

Once the model is compiled, it has support on all of
$\mathbb{R}^K$, where $K$ is the number of unconstrained parameters
needed to define the actual parameters defined in the model.

The details of section need not be understood in order to use
\Stan for well-behaved models.  Understanding the sampling behavior
of \Stan fully requires understanding these transforms.


\section{Changes of Variables}\label{change-of-variables.section}

The support of a random variable $X$ with density $p_X(x)$ is that
subset of values for which it has non-zero density,
%
\[
\mbox{support}(X) = \{ x | p_X(x) > 0 \}.
\]

If $f$ is a total function defined on the support of $X$, then $Y =
f(X)$ is a new random variable.  This section shows how to compute the
probability density function of $Y$ for well-behaved transforms $f$
and the rest of the chapter details the transforms used by \Stan.



\subsection{Univariate Changes of Variables}

Suppose $X$ is one dimensional and $f: \mbox{support}(X) \rightarrow
\mathbb{R}$ is a one-to-one, monotonic function with a differentiable
inverse $f^{-1}$.  Then the density of $Y$ is given by
%
\[
p_Y(y) = p_X(f^{-1}(y))  
         \,
         \left| \, \frac{d}{dy} f^{-1}(y)\, \right|.
\]


\subsection{Multivariate Changes of Variables}

An absolute derivative measures how the scale of the transformed
variable changes with respect to the underlying variable.  The
multivariate generalization of absolute derivatives is the absolute
Jacobian determinants.  The Jacobian measures the change of each
output variable relative to every input variable and the absolute
determinant uses that to determine the differential change in volume
at a given point in the parameter space.

Suppose $X$ is a $K$-dimensional random variable with probability
density function $p_X(x)$.  A new random variable $Y = f(X)$ may be
defined by transforming $X$ with a suitably well-behaved function $f$.
It suffices for what follows to note that if $f$ is one-to-one
and its inverse $f^{-1}$ has a well-defined Jacobian, then the
density of $Y$ is
%
\[
p_Y(y) = p_X(g(y)) \, \left| \, \det \, J_g(y) \, \right|,
\]
%
where $\det{}$ is the matrix determinant operation and $J_{f^{-1}}(y)$ is
the Jacobian of $f^{-1}$ evaluated at $y$.  The latter is defined by
\[
J_{f^{-1}}(y) = 
\left[
\begin{array}{ccc}\displaystyle
\frac{\partial y_1}{\partial x_1}
& \cdots
& \displaystyle \frac{\partial y_1}{\partial x_{K}}
\\[6pt]
\vdots & \vdots & \vdots
\\
\displaystyle\frac{\partial y_{K}}{\partial x_1}
& \cdots
& \displaystyle\frac{\partial y_{K}}{\partial x_{K}}
\end{array}
\right].
\]
%
If the Jacobian is a triangular matrix, the determinant reduces to the
product of the diagonal entries,
%
\[
\det \, J_{f^{-1}}(y)
= \prod_{k=1}^K \frac{\partial y_k}{\partial x_k}.
\]
%
Triangular matrices naturally arise in situations where the variables
are ordered, for instance by dimension, and each variable's
transformed value depends on the previous variable's transformed
values.  Diagonal matrices, a simple form of triangular matrix,
arise if each transformed variable only depends on a single raw
variable.

\section{Lower Bounded Scalar}

\Stan uses a logarithmic transform for lower and upper bounds.  

\subsection{Lower Bound Transform}

If a variable $X$ is declared to have lower bound $a$, it is
transformed to an unbounded variable $Y$, where
%
\[
Y = \log(X - a).
\]

\subsection{Lower Bound Inverse Transform}
%
The inverse of the the lower-bound transform maps an unbounded
variable $Y$ to a variable $X$ that is bounded below by $a$ by
%
\[
X = \exp(Y) + a.
\]

\subsection{Absolute Derivative of the Lower Bound Inverse Transform}

The absolute derivative of the inverse transform is
\[
\left| \,
\frac{d}{dy} \left( \exp(y) + a \right)
\, \right|
= \exp(y).
\]
Therefore, given the density $p_X$ of $X$, the density of $Y$ is 
%
\[
p_Y(y) 
= p_X\!\left( \exp(y) + a \right) \cdot \exp(y).
\]


\section{Upper Bounded Scalar}

\Stan uses a negated logarithmic transform for upper bounds.

\subsection{Upper Bound Transform}

If a variable $X$ is declared to have an upper bound $b$, it is
transformed to the unbounded variable $Y$ by
%
\[
Y = \log(b - X).
\]

\subsection{Inverse Upper Bound Transform}
%
The inverse of the upper bound transform converts the unbounded
variable $Y$ to the variable $X$ bounded above by $b$ through
%
\[
X = b - \exp(Y).
\]

\subsection{Absolute Derivative of the Inverse Upper Bound Transform}

The absolute derivative of the inverse upper bound transform is 
\[
\left| \,
\frac{d}{dy} \left( b - \exp(y) \right)
\, \right|
= \exp(y).
\]
%
Therefore, the density of the unconstrained variable $Y$ is defined in
terms of the density of the variable $X$ with an upper bound of $b$ by
%
\[
p_Y(y) 
 =   p_X \!\left( b - \exp(y) \right) \cdot \exp(y).
\]


\section{Lower and Upper Bounded Scalar}

For lower and upper-bounded variables, \Stan uses a scaled and
translated log-odds transform.

\subsection{Log Odds and the Logistic Sigmoid}

The log-odds function is defined for $u \in (0,1)$ by
%
\[
\mbox{logit}(u) = \log \frac{u}{1 - u}.
\]
% 
The inverse of the log odds function is the logistic sigmoid, defined 
for $v \in (-\infty,\infty)$ by
%
\[
\mbox{logit}^{-1}(v) = \frac{1}{1 + \exp(-v)}.
\]
% 
The derivative of the logistic sigmoid is
%
\[
\frac{d}{dy} \mbox{logit}^{-1}(y) 
= \mbox{logit}^{-1}(y) \cdot \left( 1 - \mbox{logit}^{-1}(y) \right).
\]

\subsection{Lower and Upper Bounds Transform}

For variables constrained to be in the open interval $(a,b)$, \Stan
uses a scaled and translated log-odds transform.  If variable $X$ is
declared to have lower bound $a$ and upper bound $b$, then it is
transformed to a new variable $Y$, where
%
\[
Y = \mbox{logit} \left( \frac{X - a}{b - a} \right).
\]
%

\subsection{Lower and Upper Bounds Inverse Transform}

The inverse of this transform is
%
\[
X = a + (b - a) \cdot \mbox{logit}^{-1}(Y).
\]
%

\subsection{Absolute Derivative of the Lower and Upper Bounds Inverse
  Transform}

The absolute derivative of the inverse transform is given by
\[
\left|  \frac{d}{dy} a + (b - a) \cdot \mbox{logit}^{-1}(y)
    \right|
= (b - a)
    \cdot \mbox{logit}^{-1}(y)
    \cdot \left( 1 - \mbox{logit}^{-1}(y) \right).
\]
Therefore, the density of the transformed variable $Y$ is
%
\[
p_Y(y) 
= 
 p_X \! \left( a + (b - a) \cdot \mbox{logit}^{-1}(y) \right)
    \cdot (b - a)
    \cdot \mbox{logit}^{-1}(y)
    \cdot \left( 1 - \mbox{logit}^{-1}(y) \right).
\]
%
Despite its apparent complexity, $\mbox{logit}^{-1}(y)$, and hence
$\exp(-y)$, need only be evaluated once.


\section{Positive Ordered Vector}

For some modeling tasks, a vector-valued random variable $X$ is
required with support on positive, ordered sequences.  One example is
the set of cut points in ordinal logistic regression.  

In constraint terms, a positive, ordered vector $x \in \mathbb{R}^K$
is a vector that satisfies
\[
0 < x_1
\]
%
and for $2 \leq k \leq K$,
\[
x_{k-1} < x_k
\]
%

\subsection{Positive Ordered Transform}

\Stan's transform follows the constraint directly.  It maps a vector
$x \in \mathbb{R}^{K}$ to a vector $f(x) = y \in \mathbb{R}^K$ by setting
%
\[
y_1 = f_1(x) = \log x_1
\] 
%
and for $2 \leq k \leq K$,
\[
y_k = f_k(x) = \log \left( x_{k} - x_{k-1} \right).
\]

\subsection{Positive Ordered Inverse Transform}

The inverse transform $x = f^{-1}(y)$ satisfies
%
\[
x_1 = \exp(y_1)
\]
%
and for $2 \leq k \leq K$, 
\[
x_k = x_{k-1} + \exp(y_k) = \sum_{k' =1}^{k} \exp(y_{k'}).
\]

\subsection{Absolute Jacobian Determinant of the Positive Ordered
  Inverse Transform}

The Jacobian of the inverse transform $f^{-1}$ is lower triangular,
with diagonal elements for $1 \leq k \leq K$ of
\[
J_{k,k} = \frac{\partial}{\partial y_k} f_k^{-1}(y) = \exp(y_k).
\]
%
Because of the triangularity and the positivivity of the $x_k$ and
their differences, the absolute determinant of the Jacobian is
%
\[
\left| \, \det \, J \, \right|
\ = \ 
\prod_{k=1}^K J_{k,k}
\ = \ 
\prod_{k=1}^K \exp(y_k).
\]


Putting this all together, if $p_X$ is the density of $X$, then the
transformed variable $Y$ has density $p_Y$ given by
%
\[
p_Y(y)
= p_X(f^{-1}(y)) 
\
\prod_{k=1}^K \exp(y_k).
\]


\section{Unit Simplex}

The parameter of the $K$-dimensional categorical distribution must lie
in the unit $K$-simplex.  Consequently, simplex-constrained variables show
up in multivariate discrete models of all kinds.  

The $K$-simplex is the set of points $x \in \mathbb{R}^K$ such that
for $1 \leq k \leq K$, 
\[ 
x_k > 0,
\] 
and
\[
\sum_{k=1}^K x_k = 1.
\]
%   
An alternative definition is to take the hull of the convex closure of
the vertices.  For instance, in 2-dimensions, the basis points are the
extreme values $(0,1)$, and $(1,0)$ and the unit 2-simplex is interval
with these as the end points.  In 3-dimensions, the basis is
$(0,0,1)$, $(0,1,0)$ and $(1,0,0)$ and the unit 3-simplex is the
triangle with these vertices.  As these examples illustrate, the
simplex always picks out a subspace of $K-1$ dimensions from
$\mathbb{R}^K$.

A point $x$ in the $K$-simplex is fully determined by its first $K-1$
dimensions, because rearranging terms in the constraint yields
%
\[
x_K = 1 - \sum_{k=1}^{K-1} x_k.
\]
%

\subsection{Inverse Unit Simplex Transform}

Stan employs a transform whose inverse may be understood using a
stick-breaking metaphor.  A simplex is determined by taking a stick of
unit length, breaking a piece off, the length of which is $x_1$.  Then
$x_2$ is determined by breaking a piece from what's left.  A total of
$K-1$ pieces are broken off, determining $x_1,\ldots,x_{K-1}$.  To
complete the metaphor, the length of the remaining piece after $K-1$
pieces are broken off determines $x_K$.

The simplex transform $f$ is most easily understood in terms of its
inverse $x = f^{-1}(y)$, which maps a point in $y \in
\mathbb{R}^{K-1}$ to a point $x$ in the $K$-simplex.  An intermediate
vector $z \in \mathbb{R}^{K-1}$, whose coordinates $z_k$ represent 
the proportion of the stick broken off in step $k$, is defined
elementwise for $1 \leq k < K$ by
%
\[
z_k = \mbox{logit}^{-1} \left( y_k 
                             - \mbox{logit} \left( \frac{1}{K - k + 1}
                                            \right)
                       \right).
\]
%
The logit term in the above definition adjusts the transform so that a
zero vector $y$ is mapped to $(1/K,\ldots,1/K)$.  For instance, if
$y_1 = 0$, then $z_1 = 1/K$; if $y_2 = 0$, then $z_2 = 1/(K-1)$; and
if $z_{K-1} = 0$, then $z_{K-1} = 1/2$.  This ensures that random
initializations for categorical distribution parameters are
initialized around a parameter value when $y = 0$ representing the
uniform distribution.

The break proportions $z$ are applied to determine the stick sizes and
resulting value of $x_k$ for $1 \leq k < K$ by
%
\[
x_k = 
\left( 1 - \sum_{k'=1}^{k-1} x_{k'} \right) z_k.
\]
%
The summation term represents the length of stick left at stage $k$.
This is multiplied by the break proportion $z_k$ to yield $x_k$.
Because $x$ lines in a $K$-simplex, $x_K$ is determined from
$x_1,\ldots,x_{K-1}$.

\subsection{Absolute Jacobian Determinant of the Inverse Unit Simplex
  Transform}

The Jacobian $J$ of the inverse transform $f^{-1}$ is
lower-triangular, with diagonal entries
\[
J_{k,k}
=
\frac{\partial x_k}{\partial y_k}
=
\frac{\partial x_k}{\partial z_k} \,
\frac{\partial z_k}{\partial y_k},
\]
%
where
\[
\frac{\partial z_k}{\partial y_K} 
= \frac{\partial}{\partial z_k} 
   \mbox{logit}^{-1} \left(
                       y_k - \mbox{logit} \left( \frac{1}{K-k+1}
                                          \right)
                    \right)
= z_k (1 - z_k),
\]
%
and
%
\[
\frac{\partial x_k}{\partial z_k}
=
\left( 
  1 - \sum_{k' = 1}^{k-1} x_{k'}
   \right)
.
\]
%
Note that the definition is recursive, definining $x_k$ in terms of
$x_{1},\ldots,x_{k-1}$.

Because the Jacobian $J$ of $f^{-1}$ is lower triangular and positve, its
absolute determinant reduces to
%
\[
\left| \, \det J \, \right|
\ = \
\prod_{k=1}^{K-1} J_{k,k}
\ = \
\prod_{k=1}^{K-1} 
z_k
\, 
(1 - z_k)
\
\left(
1 - \sum_{k'=1}^{k-1} x_{k'}
\right)
.
\]
%
Thus the transformed variable $Y = f(X)$ has a density given by
%
\[
p_Y(y) 
= p_X(f^{-1}(y))
\,
\prod_{k=1}^{K-1} 
z_k
\, 
(1 - z_k)
\
\left(
1 - \sum_{k'=1}^{k-1} x_{k'}
\right)
.
\]
%
This formula looks more complicated than it is.  It only involves a
single exponential function evaluation involved (in the logistic
sigmoid applied to $y_k$ to produce $z_k$);  everything else is just
basic arithmetic and keeping track of the remaing stick length.

\subsection{Unit Simplex Transform}

The transform $Y = f(X)$ can be derived by reversing the stages of the
inverse transform.  Working backwards, given the break proportions
$z$, $y$ is defined elementwise by
%
\[
y_k 
= \mbox{logit}(z_k)
+ \mbox{logit}\left(
   \frac{1}{K-k+1}
   \right)
.
\]
%
The break proportions $z_k$ are defined to be the ratio of $x_k$ to
the length of stick left after the first $k-1$ pieces have been broken
off, 
%
\[
z_k 
= \frac{x_k}
       {1 - \sum_{k' = 1}^{k-1} x_k}
.
\]

\section{Correlation Matrices}

A correlation matirx is a symmetric, positive-definite matrix with a
unit diagonal.  To deal with this rather complicated constraint, \Stan
implements the transform of (Lewandowski, Kurowicka, and Joe 2009),
henceforth the \LKJ-transform.  The number of free parameters required
to specify a $K \times K$ correlation matrix is $K \choose 2$.

\subsection{Correlation Matrix Inverse Transform}

It is easiest to specify this transform in reverse, going from its $K
\choose 2$ parameter basis to a correlation matrix.  The basis will
actually be broken down into two steps.  To start, suppose $y$
consists of $K \choose 2$ unconstrained values that are transformed via
the bijective function $\tanh : \mathbb{R} \rightarrow (0,1)$ 
%
\[
\tanh x = \frac{\exp(2x) - 1}{\exp(2x) + 1}.
\]
%
Then, define a $K \times K$ array $z$ whose strict upper triangle is 
filled from left-to-right, top-to-bottom with the transformed parameters.
For example, in the $4 \times 4$ case, there are ${4 \choose 2}$ values
arranged as
%
\[
z 
=
\left[
\begin{array}{cccc}
0 & \tanh y_1 & \tanh y_2 & \tanh y_4
\\
0 & 0 & \tanh y_3 & \tanh y_5
\\
0 & 0 & 0 & \tanh y_6
\\
0 & 0 & 0 & 0
\end{array}
\right]
.
\]
%
Lewandowski et al.\ show how to bijectively map the array $z$ to a correlation
matrix $x$.  The entry $z_{i,j}$ for $i < j$ is interpreted as the
canonical partial correlation (\CPC) between $i$ and $j$, which is the
correlation between $i$'s residuals and $j$'s residuals when both $i$
and $j$ are regressed on all variables $i'$ such that $i'< i$.
In the case of $i=1$, there are no earlier variables, 
so $z_{i,j}$ is just the Pearson correlation between $i$ and $j$.

In \Stan, the \LKJ transform is reformulated in terms of a Cholesky factor $w$
of the final correlation matrix (REMIND BEN TO GIVE YOU A CITE), defined for $1 \leq i,j \leq K$ by
%
\[
w_{i,j} = 
\left\{
\begin{array}{cl}
%
0 & \mbox{if } i > j,
\\[4pt]
1 & \mbox{if } 1 = i = j,
\\[12pt]
\prod_{i'=1}^{i - 1} \left( 1 - z_{i'\!,\,j}^2 \right)^{1/2}
& \mbox{if } 1 < i = j,
\\[12pt]
z_{i,j} & \mbox{if } 1 = i < j, \mbox{ and}
\\[12pt]
z_{i,j} \, \prod_{i'=1}^{i-1} \left( 1 - z_{i'\!,\,j}^2 \right)^{1/2}
& \mbox{ if } 1 < i < j.
%
\end{array}
\right.
\]
%
This does not require as much computation per matrix entry as it may appear; 
calculating the rows in terms of earlier rows yields the more manageable
%
\[
w_{i,j} = 
\left\{
\begin{array}{cl}
%
0 & \mbox{if } i > j,
\\[4pt]
1 & \mbox{if } 1 = i = j, 
\\[8pt]
z_{i,j} & \mbox{if } 1 = i < j, \mbox{ and}
\\[8pt]
z_{i,j} \ w_{i-1,j} \left( 1 - z_{i-1,j}^2 \right)^{1/2}
& \mbox{ if } 1 < i \leq j.
%
\end{array}
\right.
\]
Given the upper-triangular Cholesky factor $w$, the final correlation
matrix is
\[
x = w^{\top} w.
\]

Lewandowski et al.\ show that the determinant of the correlation
matrix can be defined in terms of the CPCs as
%
\[
\mbox{det} \, x = \prod_{i=1}^{K-1} \ \prod_{j=i+1}^K \ (1 - z_{i,j}^2)
 = \prod_{1 \leq i < j \leq K} (1 - z_{i,j}^2),
\]
which is also the square of the determinant of the triangular $w$.

\subsection{Absolute Jacobian Determinant of the Correlation
  Matrix Inverse Transform}

\subsection{Correlation Matrix Transform}

The correlation transform is defined by reversing the steps of the
inverse transform defined in the previous section.  

Starting with a correlation matrix $x$, the first step is to find the
unique upper triangular $w$ such that $x = w w^{\top}$.  Because $x$
is positive definite, this can be done by applying the Cholesky
decomposition,
\[
w = \mbox{cholesky}(x).
\]


The next step from the Cholesky factor $w$ back to the array $z$ of
{\CPC}s is simplified by the ordering of the elements in the
definition of of $w$, which when inverted yields
%
\[
z_{i,j} =
\left\{
\begin{array}{cl}
0 & \mbox{if } i \leq j,
\\[8pt]
w_{i,j} & \mbox{if } 1 = i < j, \mbox{ and}
\\[8pt]
{w_{i,j}}
\
\prod_{i'=1}^{i-1} \left( 1 - z_{i'\!,j}^2 \right)^{-2}
& \mbox{if } 1 < i < j.
\end{array}
\right.
\]
The final stage of the transform reverses the tanh transform, which
is given by
\[
\tanh^{-1} v = \frac{1}{2} \log \left( \frac{1 + v}{1 - v} \right),
\]
and is also known as the Fisher transformation.


\section{Covariance Matrices}

In order for a $K \times K$ matrix to be used as a covariance matrix,
it must be symmetric and positive definite.  A $K \times K$ matrix $x$ 
is positive definite if for every $K$-vector $a$,
%
\[
a^{\top} x \,  a > 0.
\]
%
A matrix $x$ is said to be positive semi-definite if the constraint
is relaxed to $a^{\top} x \, a \geq 0$.

\subsection{Covariance Matrix Transform}

\Stan's covariance transform is based on a Cholesky decomposition
composed with a log transform of the positive-constrained diagonal
elements.  

If $x$ is a covariance matrix (i.e., a symmetric, positive definite
matrix), then there is a unique lower-triangular matrix $z =
\mbox{cholesky}(x)$ with positive diagonal entries, called a Cholesky
factor, such that
\[
x = z \, z^{\top}.
\]
The off-diagonal entries of the Cholesky factor $z$ are unconstrained,
but the diagonal entries $z_{k,k}$ nmust be positive for $1 \leq k
\leq K$.

To complete the transform, the diagonal is log-transformed to produce
a fully unconstrained lower-triangular matrix $y$ defined by
\[
y_{m,n} = 
\left\{
\begin{array}{cl}
0 & \mbox{if } m < n,
\\[4pt]
\log z_{m,m} & \mbox{if } m = n, \mbox{ and}
\\[4pt]
z_{m,n} & \mbox{if } m > n.
\end{array}
\right.
\]

\subsection{Inverse Covariance Matrix Transform}

The inverse transform must reverses the two steps of the transform.
Given an unconstrained lower-triangular $K \times K$ matrix $y$, the
first step is to recover the intermediate matrix $z$ by reversing the
log transform,
\[
z_{m,n} = 
\left\{
\begin{array}{cl}
0 & \mbox{if } m < n,
\\[4pt]
\exp(y_{m,m}) & \mbox{if } m = n, \mbox{ and}
\\[4pt]
y_{m,n} & \mbox{if } m > n.
\end{array}
\right.
\]
%
The covariance matrix $x$ is recovered from its Cholesky factor $z$ by
taking
%
\[
x = z \, z^{\top}.
\]

\subsection{Absolute Jacobian Determinant of the Inverse Covariance
  Matrix Transform}

The Jacobian determinant is the product of the Jacobian determinants
of the exponential transform from the unconstrained lower-triangular
matrix $y$ to matrix $z$ with positive diagonals and the product
transform from the Cholesky factor $z$ to $x$.

The transform from unconstrained $y$ to Cholesky factor $z$ has a
diagonal Jacobian, so its Jacobian determinant is
%
\[
\prod_{k=1}^K  \frac{d}{d_{y_{k,k}}} \, \exp(y_{k,k})
\ = \ 
\prod_{k=1}^K \exp(y_{k,k})
\ = \
\prod_{k=1}^K z_{k,k},
\]
which is always positive.

The Jacobian of the second transform from the Cholesky factor $z$ to
the covariance matrix $x$ is also triangular, with diagonal entries
corresponding to pairs $m,n$ with $m \geq n$, defined by
\[
\frac{\partial}{\partial z_{m,n}}
\left( z \, z^{\top} \right)_{m,n}
\ = \
\frac{\partial}{\partial z_{m,n}}
\left( \sum_{k=1}^K z_{m,k} \, z_{n,k} \right)
\ = \
\left\{
\begin{array}{cl}
2 \, z_{n,n} & \mbox{if } m = n \mbox{ and }
\\[4pt]
z_{n,n} & \mbox{if } m > n.
\end{array}
\right.
.
\]
%
The absolute Jacobian determinant of the second transform is thus
\[
2^{K} 
\
\prod_{m = 1}^{K} \ \prod_{n=1}^{m} z_{n,n}.
\]
Finally, the full absolute Jacobian determinant of the inverse
covariance matrix transform from the unconstrained lower-triangular 
$y$ to a symmetric, positive definite matrix $x$ is
\[
2^{K} 
\
\left( \prod_{k=1}^K z_{k,k} \right)
\left( \prod_{m = 1}^{K} \ \prod_{n=1}^{m} z_{n,n} \right).
\]



% \section{Covariance Matrices}

% Covariance matrices are just scaled correlation matrices.  This
% requires an additional $K$ positive scaling parameters, for a total
% requirement of $K + {K \choose 2}$ parameters to specify a covariance
% matrix.  

% \subsection{Inverse Covariance Matrix Transform}

% Suppose $y$ is a $K \choose 2$-dimensional array specifying the $K
% \times K$ correlation matrix $x$ as specified by the correlation
% matrix inverse transform described in the previous section.  

% Let $y'$ be a $K$-dimensional vector of unconstrained scaling
% parameters.  An exponential transform converts these to positive
% values component-wise, by
% %
% \[
% u = \exp(y').
% \]
% %
% The covariance matrix is the scaled version of the correlation matrix
% $x$,
% \[
% v \ = \ \mbox{diag}(u) \ x \ \mbox{diag}(u)
%   \ = \ \left(\mbox{diag}(u) \, z\right) \left(\mbox{diag}(u) \, z)\right)^{\top},
% \]
% %
% where $\mbox{diag}(u)$ is the diagonal matrix with diagonal $u$.

% \subsection{Absolute Jacobian Determinant of the Covariance
%   Matrix Inverse Transform}

% Each covariance is equal to the correlation between two variables, 
% times the product of their standard deviations. Thus, the Jacobian
% matrix for the transform from $K \choose 2$ correlations to 
% $K \choose 2$ covariances is diagonal, and each diagonal cell is
% the product of a pair of standard deviations. The determinant of
% this Jacobian is strictly positive and is the product of every
% unique pair of standard deviations. This Jacobian determinant can
% be combined with the Jacobian determinant of the correlation matrix
% inverse transform and the Jacobian determinants for the transformations
% from unbounded parameters to bounded CPCs and unbound parameters to
% bounded standard deviations to yield the absolute Jacobian determinant
% of the covariance matrix inverse transform. 

% \subsection{Covariance Matrix Transform}

% The covariance matrix transform just reverses the steps of the inverse
% transform.  The first steps here are to derive the scaling factors $u$
% and the correlation matrix $x$ from the covariance matrix $v$.
% The correlation matrix $x$ has a unit diagonal, allowing $u$ to be
% recovered componentwise through
% %
% \[
% u_k = \sqrt{v_{k,k}}.
% \]
% %
% The unconstrained scaling factors themselves are then recovered by
% reversing the exponentiation that created them, with
% %
% \[
% y'_k = \log u_k.
% \]
% %
% Given the scaling factors $u$, it is straightforward to recover the
% correlation matrix $x$ from the covariance matrix $v$ by reversing the
% multiplications by diagonals
% %
% \[
% x = \mbox{diag}(u)^{-1} \ v \ \mbox{diag}(u)^{-1}.
% \]
% The matrix $\mbox{diag}(u)$ is invertible because it is diagonal and
% the entries are positive.  


\chapter{The C++ Model Class}

The generated \Cpp class extends a built-in \Stan abstract
base class for probability models.  Instances of the class are
constructed from a specified data vector $y$.  The data vector $y$
determines the dimensionality $K$ of the parameter vector $\theta$,
which in general may depend on size constants in $y$.  The class
implements a method that takes a parameter $K$-vector $\theta$ as
argument and returns the (unnormalized) total log probabilty,
\[
\theta 
\mapsto 
\log p(y,\theta) 
\]
The second method returns the gradient of the (unnormalized) total
probability as a function of a parameter $K$-vector $\theta$,
\[
\theta
\mapsto
\nabla_{\theta} \log p(y,\theta)
= ( \frac{\partial}{\partial\theta_1} \log p(y,\theta),
  \ldots, 
  \frac{\partial}{\partial\theta_K} \log p(y,\theta) ),
\]

The class computes gradients using accurate and efficient reverse-mode
algorithmic differentiaton.  The cost of computing the gradient is
a small multiple of the cost of computing the log probability.  The
cost inovlves a bounded amount of extra bookkeeping for each 
subexpression involved in computing the log probability.  Unlike
in the calculation of finite differences, the extra bookkeeping is
not dependent on the dimensionality of the parameter vector.


\chapter{Optimizing \Stan Code}\label{optimization.chapter}


\appendix

\part*{Appendices}
\addcontentsline{toc}{part}{Appendices}


\chapter{Installation}\label{install.appendix}

\chapter{BNF Grammars for \Stan}

This appendix provides a modular Backus-Naur form (\BNF) grammar for
the Stan modeling language.

\section{Variable Declarations}

\Stan's grammar for variable declarations is
%
\begin{quote}
\begin{Verbatim}
var_decl ::= var_type var_name ?dims

var_type ::= int ?int_range
          | real ?real_range
          | vector '(' int_expression ')'
          | pos_ordered '(' int_expression ')'
          | simplex '(' int_expression ')'
          | row_vector '(' int_expression ')'
          | matrix '(' int_expression ',' int_expression ')'
          | corr_matrix '(' int_expression ')'
          | cov_matrix '(' int_expression ')'

int_range ::= '(' int_expression ',' ?int_expression ')'
          | '('  ','  int_expression ')'

real_range ::= '(' real_expression ',' ?real_expression ')'
          | '('  ','  real_expression ')'


dims ::= '['  int_expression (',' int_expression)*  ']'
\end{Verbatim}
\end{quote}

\section{Expressions}

\Stan's grammar for expressions is 
%
\begin{quote}
\begin{Verbatim}
expression ::= literal
             | variable
             | expression infixOp expression
             | prefixOp expression
             | expression postfixOp
             | expression '[' expressions ']'
             | function '(' ?expressions ')'
             | '(' expression ')'

expressions ::= 
              | expression
              | expression ',' expressions
\end{Verbatim}
\end{quote}

\section{Statements}

\Stan's grammar for statements is
%
\begin{quote}
\begin{Verbatim}
statement 
::= 
 | lhs '<-' expression ';'
  | expression '~' identifier '(' ?expressions ')' ?truncation ';'
  | 'for' '(' identifier 'in' expression ':' expression ')' statement
  | '{' var_decl* statement+ '}'
  | ';'

truncation ::= 'T' '(' ?expression ',' ?expression ')' 

lhs ::= identifier
      | identifier '[' expressions ']'

\end{Verbatim}
\end{quote}



\chapter{User-Defined Functions and Gradients}\label{user-defined-functions.appendix}




\chapter*{References}
\addcontentsline{toc}{chapter}{References}

\end{document}